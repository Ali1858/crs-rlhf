{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reward score at each step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output/rl/LLama-2-7b-oasst-baseline_rl_f_crs_025_bs16_kl_002_clip_04_512_max_token_with_pad_eos_lr_141e5/eval_output\n",
      "mean reponse length for reference model 162.2 and active model 203.0\n",
      "reward for step 75 from active model is :(1.0083984375, 0.5377097496813161) and ref model is: (0.48837890625, 0.9257969541867535)\n",
      "******************************\n",
      "output/rl/LLama-2-7b-oasst-baseline_rl_f_crs_025_bs16_kl_002_clip_04_512_max_token_with_pad_eos_lr_141e5/eval_output\n",
      "mean reponse length for reference model 151.0 and active model 179.1\n",
      "reward for step 150 from active model is :(1.10859375, 0.4505340797667253) and ref model is: (0.820703125, 0.38508750812771847)\n",
      "******************************\n",
      "output/rl/LLama-2-7b-oasst-baseline_rl_f_crs_025_bs16_kl_002_clip_04_512_max_token_with_pad_eos_lr_141e5/eval_output\n",
      "mean reponse length for reference model 120.1 and active model 152.6\n",
      "reward for step 225 from active model is :(0.84140625, 0.5227883392971558) and ref model is: (0.67001953125, 0.7673361142912095)\n",
      "******************************\n",
      "output/rl/LLama-2-7b-oasst-baseline_rl_f_crs_025_bs16_kl_002_clip_04_512_max_token_with_pad_eos_lr_141e5/eval_output\n",
      "mean reponse length for reference model 206.3 and active model 143.3\n",
      "reward for step 300 from active model is :(1.08203125, 0.19805881682438428) and ref model is: (0.5365234375, 0.8244159133626464)\n",
      "******************************\n",
      "output/rl/LLama-2-7b-oasst-baseline_rl_f_crs_025_bs16_kl_002_clip_04_512_max_token_with_pad_eos_lr_141e5/eval_output\n",
      "mean reponse length for reference model 169.4 and active model 139.1\n",
      "reward for step 375 from active model is :(0.837890625, 0.37747494646013013) and ref model is: (0.809765625, 0.7340841553385692)\n",
      "******************************\n",
      "output/rl/LLama-2-7b-oasst-baseline_rl_f_crs_025_bs16_kl_002_clip_04_512_max_token_with_pad_eos_lr_141e5/eval_output\n",
      "mean reponse length for reference model 182.7 and active model 157.0\n",
      "reward for step 450 from active model is :(0.99853515625, 0.35310675649863366) and ref model is: (1.1083984375, 0.492053591965065)\n",
      "******************************\n",
      "output/rl/LLama-2-7b-oasst-baseline_rl_f_crs_025_bs16_kl_002_clip_04_512_max_token_with_pad_eos_lr_141e5/eval_output\n",
      "mean reponse length for reference model 116.5 and active model 180.9\n",
      "reward for step 525 from active model is :(1.090234375, 0.38742616011443476) and ref model is: (0.6501953125, 0.637459547965962)\n",
      "******************************\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "def save_json(data, file_path):\n",
    "    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "    with open(file_path, 'w', encoding='utf-8') as file:\n",
    "        json.dump(data, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "\n",
    "def load_records(record_path):\n",
    "    # print(f'loading records for file:{record_path}')\n",
    "    with open(record_path,'r') as f:\n",
    "        records = json.load(f)\n",
    "    return records\n",
    "\n",
    "import numpy as np\n",
    "def deserialize(records,step):\n",
    "    reward = []\n",
    "    ref_reward = []\n",
    "    model_output = []\n",
    "    reference_output = []\n",
    "    ref_len = []\n",
    "    m_len = []\n",
    "\n",
    "    for record in records:\n",
    "        reward.append(record[\"reward\"])\n",
    "        ref_reward.append(record[\"ref_reward\"])\n",
    "        model_output.append({'instruction':record[\"query\"],'output':record[\"response\"]})\n",
    "        reference_output.append({'instruction':record[\"query\"],'output':record[\"ref_response\"]})\n",
    "\n",
    "\n",
    "        ref_len.append(len(record[\"ref_response\"].split()))\n",
    "        m_len.append(len(record[\"response\"].split()))\n",
    "    \n",
    "    print(f'mean reponse length for reference model {np.mean(ref_len)} and active model {np.mean(m_len)}')\n",
    "    # save_json(model_output,f'{root}/clean_data/output_{step}.json')\n",
    "    # save_json(model_output,f'{root}/clean_data/reference_{step}.json')\n",
    "\n",
    "\n",
    "    return reward, ref_reward\n",
    "\n",
    "\n",
    "# root = \"output/rl/LLama-2-7b-oasst-baseline_rl_abs_quality_rw_075_bs16_kl_002_clip_04_512_max_token_with_pad_eos_lr_141e5/eval_output\"\n",
    "# root = \"output/rl/LLama-2-7b-oasst-baseline_rl_abs_quality_rw_075_bs16_kl_002_clip_04_512_max_token_with_pad_eos_lr_141e5_r32_alpha_64/eval_output\"\n",
    "# root = \"output/rl/LLama-2-7b-oasst-baseline_rl_bs16_kl_015_clip_035_512_max_token_with_pad_eos_lr_741e5/eval_output\"\n",
    "# root = \"output/rl/LLama-2-7b-oasst-baseline_rl_bs16_kl_001_clip_04_512_max_token_with_pad_eos_lr_141e5_10p_data_rank/eval_output\"\n",
    "# root = \"output/rl/LLama-2-7b-oasst-baseline_rl_abs_quality_rw_075_bs16_kl_002_clip_04_512_max_token_with_pad_eos_lr_141e5_logits_adjusted/eval_output\"\n",
    "# root = \"output/rl/LLama-2-7b-oasst-baseline_rl_bs16_kl_001_clip_04_512_max_token_with_pad_eos_lr_141e5/eval_output\"\n",
    "\n",
    "root = \"output/rl/LLama-2-7b-oasst-baseline_rl_bs16_kl_001_clip_04_512_max_token_with_pad_eos_lr_141e5/eval_output\"\n",
    "root = \"output/rl/LLama-2-7b-oasst-baseline_rl_f_crs_025_bs16_kl_002_clip_04_512_max_token_with_pad_eos_lr_141e5/eval_output\"\n",
    "# root = \"output/rl/LLama-2-7b-oasst-baseline_rl_abs_quality_rw_075_bs16_kl_002_clip_04_512_max_token_with_pad_eos_lr_141e5_logits/eval_output\"\n",
    "for step in [75,150,225,300,375,450,525]:\n",
    "    print(root)\n",
    "    try:\n",
    "        record_path = f\"{root}/responses_rewards_step_{step}.json\"\n",
    "        records = load_records(record_path)\n",
    "        reward,ref_reward = deserialize(records,step)\n",
    "        print(f'reward for step {step} from active model is :{np.mean(reward),np.std(reward)} and ref model is: {np.mean(ref_reward),np.std(ref_reward)}')\n",
    "        print('***'*10)\n",
    "    except Exception as e:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpaca_eval --model_outputs 'alpaca_eval/clean_data/output_150.json' --reference_outputs 'alpaca_eval/clean_data/output_300.json' --annotators_config 'alpaca_eval_gpt4_turbo_fn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data for alpaca_eval RLHF vs SFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading records for a file at path: output/rl/LLama-2-7b-oasst-baseline_rl_bs16_kl_002_clip_04_512_max_token_with_pad_eos_lr_141e5/eval_v1_double_check/final_p_09_t_08_rlhf_output.json\n",
      "Mean of 100 reward for responses in final_p_09_t_08_rlhf_output.json is 2.37808837890625, median is 2.515625 and standard deviation is 1.306530467580256\n",
      "Mean of 100 response is 132.21, median is 126.0 and standard deviation is 63.493510692038434\n",
      "==============================\n",
      "loading records for a file at path: output/rl/LLama-2-7b-oasst-baseline_rl_bs16_kl_002_clip_04_512_max_token_with_pad_eos_lr_141e5/eval_v1_double_check/final_p_01_run_1_rlhf_output.json\n",
      "Mean of 100 reward for responses in final_p_01_run_1_rlhf_output.json is 1.832625732421875, median is 1.85546875 and standard deviation is 1.337480715881685\n",
      "Mean of 100 response is 136.82, median is 129.0 and standard deviation is 70.69107157201678\n",
      "==============================\n",
      "loading records for a file at path: output/rl/LLama-2-7b-oasst-baseline_rl_bs16_kl_002_clip_04_512_max_token_with_pad_eos_lr_141e5/eval_v1_double_check/final_p_01_run_1_sft_output.json\n",
      "Mean of 100 reward for responses in final_p_01_run_1_sft_output.json is 1.41296142578125, median is 1.50390625 and standard deviation is 1.454425929814641\n",
      "Mean of 100 response is 180.4, median is 179.0 and standard deviation is 95.11214433499015\n",
      "==============================\n",
      "loading records for a file at path: output/rl/LLama-2-7b-oasst-baseline_rl_bs16_kl_002_clip_04_512_max_token_with_pad_eos_lr_141e5/eval_v1_double_check/final_p_09_t_08_sft_output.json\n",
      "Mean of 100 reward for responses in final_p_09_t_08_sft_output.json is 2.24897705078125, median is 2.375 and standard deviation is 1.4454328203153168\n",
      "Mean of 100 response is 177.83, median is 179.5 and standard deviation is 95.32607775420115\n",
      "==============================\n",
      "loading records for a file at path: output/rl/LLama-2-7b-oasst-baseline_rl_abs_quality_rw_075_bs16_kl_002_clip_04_512_max_token_with_pad_eos_lr_141e5_logits/eval_v1_double_check/final_p_09_t_08_rlhf_output.json\n",
      "Mean of 100 reward for responses in final_p_09_t_08_rlhf_output.json is 0.91205322265625, median is 0.943359375 and standard deviation is 0.42367884364122066\n",
      "Mean of 100 response is 192.48, median is 194.5 and standard deviation is 80.42891022511743\n",
      "==============================\n",
      "loading records for a file at path: output/rl/LLama-2-7b-oasst-baseline_rl_abs_quality_rw_075_bs16_kl_002_clip_04_512_max_token_with_pad_eos_lr_141e5_logits/eval_v1_double_check/final_p_01_run_2_rlhf_output.json\n",
      "Mean of 100 reward for responses in final_p_01_run_2_rlhf_output.json is 0.80632080078125, median is 0.85546875 and standard deviation is 0.4730416874179798\n",
      "Mean of 100 response is 183.74, median is 185.0 and standard deviation is 75.5312676975569\n",
      "==============================\n",
      "loading records for a file at path: output/rl/LLama-2-7b-oasst-baseline_rl_abs_quality_rw_075_bs16_kl_002_clip_04_512_max_token_with_pad_eos_lr_141e5_logits/eval_v1_double_check/final_p_01_run_3_rlhf_output.json\n",
      "Mean of 100 reward for responses in final_p_01_run_3_rlhf_output.json is 0.812861328125, median is 0.865234375 and standard deviation is 0.5389604272594063\n",
      "Mean of 100 response is 186.96, median is 189.0 and standard deviation is 69.61866416414495\n",
      "==============================\n",
      "loading records for a file at path: output/rl/LLama-2-7b-oasst-baseline_rl_abs_quality_rw_075_bs16_kl_002_clip_04_512_max_token_with_pad_eos_lr_141e5_logits/eval_v1_double_check/final_p_01_run_1_rlhf_output.json\n",
      "Mean of 100 reward for responses in final_p_01_run_1_rlhf_output.json is 0.801280517578125, median is 0.84375 and standard deviation is 0.44192123285035234\n",
      "Mean of 100 response is 190.52, median is 181.5 and standard deviation is 78.54749900537891\n",
      "==============================\n",
      "loading records for a file at path: output/rl/LLama-2-7b-oasst-baseline_rl_abs_quality_rw_075_bs16_kl_002_clip_04_512_max_token_with_pad_eos_lr_141e5_logits/eval_v1_double_check/final_p_01_run_1_sft_output.json\n",
      "Mean of 100 reward for responses in final_p_01_run_1_sft_output.json is 0.60927978515625, median is 0.615234375 and standard deviation is 0.5691337913830787\n",
      "Mean of 100 response is 180.19, median is 170.0 and standard deviation is 100.83805779565571\n",
      "==============================\n",
      "loading records for a file at path: output/rl/LLama-2-7b-oasst-baseline_rl_abs_quality_rw_075_bs16_kl_002_clip_04_512_max_token_with_pad_eos_lr_141e5_logits/eval_v1_double_check/final_p_09_t_08_sft_output.json\n",
      "Mean of 100 reward for responses in final_p_09_t_08_sft_output.json is 0.7256218719482422, median is 0.849609375 and standard deviation is 0.5439947675485448\n",
      "Mean of 100 response is 183.37, median is 184.5 and standard deviation is 100.937471238386\n",
      "==============================\n",
      "loading records for a file at path: output/rl/LLama-2-7b-oasst-baseline_rl_abs_quality_rw_075_bs16_kl_002_clip_04_512_max_token_with_pad_eos_lr_141e5_logits/eval_v1_double_check/final_p_01_run_3_sft_output.json\n",
      "Mean of 100 reward for responses in final_p_01_run_3_sft_output.json is 0.60398681640625, median is 0.689453125 and standard deviation is 0.5489507987472275\n",
      "Mean of 100 response is 164.01, median is 157.5 and standard deviation is 91.63148967467461\n",
      "==============================\n",
      "loading records for a file at path: output/rl/LLama-2-7b-oasst-baseline_rl_abs_quality_rw_075_bs16_kl_002_clip_04_512_max_token_with_pad_eos_lr_141e5_logits/eval_v1_double_check/final_p_01_run_2_sft_output.json\n",
      "Mean of 100 reward for responses in final_p_01_run_2_sft_output.json is 0.6795700073242188, median is 0.736328125 and standard deviation is 0.5730940439125146\n",
      "Mean of 100 response is 175.92, median is 168.0 and standard deviation is 96.86636980913448\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import json\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "\n",
    "def save_json(data, file_path):\n",
    "    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "    with open(file_path, 'w', encoding='utf-8') as file:\n",
    "        json.dump(data, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "\n",
    "def load_records(record_path):\n",
    "    print(f'loading records for a file at path: {record_path}')\n",
    "    with open(record_path,'r') as f:\n",
    "        records = json.load(f)\n",
    "    return records\n",
    "\n",
    "\n",
    "def deserialize(records,suffix):\n",
    "    reward = []\n",
    "    res_len = []\n",
    "    model_output = []\n",
    "    for record in records:\n",
    "        reward.append(record[\"reward\"])\n",
    "        res_len.append(len(record[\"response\"].split()))\n",
    "        q = record[\"query\"]\n",
    "        q = q.split(\"<|im_start|>user\\n\")[-1].split(\"<|im_end|>\\n<|im_start|>assistant\\n\")[0]\n",
    "        model_output.append({'instruction':q,'output':record[\"response\"]})\n",
    "    save_json(model_output,f'{save_dir}/alpaca_{suffix}')\n",
    "    return reward,res_len\n",
    "\n",
    "\n",
    "root = \"output/rl/LLama-2-7b-oasst-baseline_rl_bs16_kl_001_clip_04_512_max_token_with_pad_eos_lr_141e5/eval_output\"\n",
    "# root = \"output/rl/LLama-2-7b-oasst-baseline_rl_abs_quality_rw_075_bs16_kl_002_clip_04_512_max_token_with_pad_eos_lr_141e5_logits_adjusted/eval_output\"\n",
    "\n",
    "# root = \"output/rl/LLama-2-7b-oasst-baseline_rl_bs16_kl_002_clip_04_512_max_token_with_pad_eos_lr_141e5/eval_v1_double_check\"\n",
    "# root = \"output/rl/LLama-2-7b-oasst-baseline_rl_abs_quality_rw_075_bs16_kl_002_clip_04_512_max_token_with_pad_eos_lr_141e5_logits/eval_v1_double_check\"\n",
    "\n",
    " #_adjusted \"\n",
    "\n",
    "\n",
    "roots = [\"output/rl/LLama-2-7b-oasst-baseline_rl_crs_025_bs16_kl_002_clip_04_512_max_token_with_pad_eos_lr_141e5/eval_output\",\n",
    "         \"output/rl/LLama-2-7b-oasst-baseline_rl_crs_0375_bs16_kl_002_clip_04_512_max_token_with_pad_eos_lr_141e5/eval_output\",\n",
    "         \"output/rl/LLama-2-7b-oasst-baseline_rl_crs_05_bs16_kl_002_clip_04_512_max_token_with_pad_eos_lr_141e5/eval_output\",\n",
    "         \"output/rl/LLama-2-7b-oasst-baseline_rl_crs_0625_bs16_kl_002_clip_04_512_max_token_with_pad_eos_lr_141e5/eval_output\",\n",
    "         \"output/rl/LLama-2-7b-oasst-baseline_rl_crs_075_bs16_kl_002_clip_04_512_max_token_with_pad_eos_lr_141e5/eval_output\"\n",
    "         ]\n",
    "\n",
    "\n",
    "roots = [\n",
    "    \"output/rl/LLama-2-7b-oasst-baseline_rl_bs16_kl_002_clip_04_512_max_token_with_pad_eos_lr_141e5/eval_v1_double_check\",\n",
    "    \"output/rl/LLama-2-7b-oasst-baseline_rl_abs_quality_rw_075_bs16_kl_002_clip_04_512_max_token_with_pad_eos_lr_141e5_logits/eval_v1_double_check\",\n",
    "         ]\n",
    "\n",
    "for root in roots:\n",
    "    save_dir = f\"alpaca_eval/{root.split('/')[2]}\"\n",
    "\n",
    "    rlhf_output = list(glob(root+'/*_rlhf_output.json'))\n",
    "    sft_output = list(glob(root+'/*_sft_output.json'))\n",
    "    predicted_files = {\"rlhf\":rlhf_output,\n",
    "            \"sft\":sft_output}\n",
    "    for type, paths in predicted_files.items():\n",
    "        for record_path in paths:\n",
    "            fn = record_path.split('/')[-1]\n",
    "            try:\n",
    "                records = load_records(record_path)\n",
    "                reward,res_len = deserialize(records,fn)\n",
    "                print(f'Mean of {len(reward)} reward for responses in {fn} is {np.mean(reward)}, median is {np.median(reward)} and standard deviation is {np.std(reward)}')\n",
    "                print(f'Mean of {len(res_len)} response is {np.mean(res_len)}, median is {np.median(res_len)} and standard deviation is {np.std(res_len)}')\n",
    "                print('==='*10)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print('==='*10)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bs16_kl_001_clip_04p_09_t_08_rlhf_output.json\n",
      "loading records for a file at path: output/rl/LLama-2-7b-oasst-baseline_rl_bs16_kl_001_clip_04_512_max_token_with_pad_eos_lr_141e5/eval_output/final_p_09_t_08_rlhf_output.json\n",
      "Mean of 100 reward for responses in bs16_kl_001_clip_04p_09_t_08_rlhf_output.json is 0.0, median is 0.0 and standard deviation is 0.0\n",
      "Mean of 100 response is 188.77, median is 176.5 and standard deviation is 73.66435433776637\n",
      "==============================\n",
      "bs16_kl_002_clip_04p_09_t_08_rlhf_output.json\n",
      "loading records for a file at path: output/rl/LLama-2-7b-oasst-baseline_rl_bs16_kl_002_clip_04_512_max_token_with_pad_eos_lr_141e5/eval_output/final_p_09_t_08_rlhf_output.json\n",
      "Mean of 100 reward for responses in bs16_kl_002_clip_04p_09_t_08_rlhf_output.json is 0.0, median is 0.0 and standard deviation is 0.0\n",
      "Mean of 100 response is 130.66, median is 122.5 and standard deviation is 59.637105898928404\n",
      "==============================\n",
      "abs_quality_rw_075_bs16_kl_002_clip_04p_09_t_08_rlhf_output.json\n",
      "loading records for a file at path: output/rl/LLama-2-7b-oasst-baseline_rl_abs_quality_rw_075_bs16_kl_002_clip_04_512_max_token_with_pad_eos_lr_141e5_logits/eval_output/final_p_09_t_08_rlhf_output.json\n",
      "Mean of 100 reward for responses in abs_quality_rw_075_bs16_kl_002_clip_04p_09_t_08_rlhf_output.json is 0.0, median is 0.0 and standard deviation is 0.0\n",
      "Mean of 100 response is 180.95, median is 177.5 and standard deviation is 70.50835056927654\n",
      "==============================\n",
      "f_crs_0625_bs16_kl_002_clip_04p_09_t_08_rlhf_output.json\n",
      "loading records for a file at path: output/rl/LLama-2-7b-oasst-baseline_rl_f_crs_0625_bs16_kl_002_clip_04_512_max_token_with_pad_eos_lr_141e5/eval_output/final_p_09_t_08_rlhf_output.json\n",
      "Mean of 100 reward for responses in f_crs_0625_bs16_kl_002_clip_04p_09_t_08_rlhf_output.json is 0.0, median is 0.0 and standard deviation is 0.0\n",
      "Mean of 100 response is 148.71, median is 136.0 and standard deviation is 73.98355155032772\n",
      "==============================\n",
      "f_crs_025_bs16_kl_002_clip_04p_09_t_08_rlhf_output.json\n",
      "loading records for a file at path: output/rl/LLama-2-7b-oasst-baseline_rl_f_crs_025_bs16_kl_002_clip_04_512_max_token_with_pad_eos_lr_141e5/eval_output/final_p_09_t_08_rlhf_output.json\n",
      "Mean of 100 reward for responses in f_crs_025_bs16_kl_002_clip_04p_09_t_08_rlhf_output.json is 0.0, median is 0.0 and standard deviation is 0.0\n",
      "Mean of 100 response is 148.91, median is 145.0 and standard deviation is 57.84446300208863\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import json\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "\n",
    "def save_json(data, file_path):\n",
    "    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "    with open(file_path, 'w', encoding='utf-8') as file:\n",
    "        json.dump(data, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "\n",
    "def load_records(record_path):\n",
    "    print(f'loading records for a file at path: {record_path}')\n",
    "    with open(record_path,'r') as f:\n",
    "        records = json.load(f)\n",
    "    return records\n",
    "\n",
    "all_path = []\n",
    "def deserialize(records,suffix,g):\n",
    "    reward = []\n",
    "    res_len = []\n",
    "    model_output = []\n",
    "    for record in records:\n",
    "        reward.append(record[\"reward\"])\n",
    "        res_len.append(len(record[\"response\"].split()))\n",
    "        q = record[\"query\"]\n",
    "        q = q.split(\"<|im_start|>user\\n\")[-1].split(\"<|im_end|>\\n<|im_start|>assistant\\n\")[0]\n",
    "        model_output.append({'instruction':q,'output':record[\"response\"],'generator':g})\n",
    "    all_path.append(f'{save_dir}/{suffix}')\n",
    "    save_json(model_output,f'{save_dir}/{suffix}')\n",
    "    return reward,res_len\n",
    "\n",
    "\n",
    "roots = {\"025\":\"output/rl/LLama-2-7b-oasst-baseline_rl_crs_025_bs16_kl_002_clip_04_512_max_token_with_pad_eos_lr_141e5/eval_output\",\n",
    "         \"0375\":\"output/rl/LLama-2-7b-oasst-baseline_rl_crs_0375_bs16_kl_002_clip_04_512_max_token_with_pad_eos_lr_141e5/eval_output\",\n",
    "         \"05\":\"output/rl/LLama-2-7b-oasst-baseline_rl_crs_05_bs16_kl_002_clip_04_512_max_token_with_pad_eos_lr_141e5/eval_output\",\n",
    "         \"0625\":\"output/rl/LLama-2-7b-oasst-baseline_rl_crs_0625_bs16_kl_002_clip_04_512_max_token_with_pad_eos_lr_141e5/eval_output\",\n",
    "         \"075\":\"output/rl/LLama-2-7b-oasst-baseline_rl_crs_075_bs16_kl_002_clip_04_512_max_token_with_pad_eos_lr_141e5/eval_output\"\n",
    "         }\n",
    "\n",
    "\n",
    "roots = {\"rank_001\":'output/rl/LLama-2-7b-oasst-baseline_rl_bs16_kl_001_clip_04_512_max_token_with_pad_eos_lr_141e5/eval_output',\n",
    "         \"rank_002\":\"output/rl/LLama-2-7b-oasst-baseline_rl_bs16_kl_002_clip_04_512_max_token_with_pad_eos_lr_141e5/eval_output\",\n",
    "         \"abs\":\"output/rl/LLama-2-7b-oasst-baseline_rl_abs_quality_rw_075_bs16_kl_002_clip_04_512_max_token_with_pad_eos_lr_141e5_logits/eval_output\",\n",
    "         \"crs_0625\":\"output/rl/LLama-2-7b-oasst-baseline_rl_f_crs_0625_bs16_kl_002_clip_04_512_max_token_with_pad_eos_lr_141e5/eval_output\",\n",
    "         \"crs_025\":\"output/rl/LLama-2-7b-oasst-baseline_rl_f_crs_025_bs16_kl_002_clip_04_512_max_token_with_pad_eos_lr_141e5/eval_output\"\n",
    "\n",
    "        }\n",
    "\n",
    "\n",
    "save_dir = f\"alpaca_eval/final\"#crs_hp_tuning\"\n",
    "# record_fn = 'tuning_p_09_t_08_rlhf_output.json'\n",
    "record_fn = 'final_p_09_t_08_rlhf_output.json'\n",
    "# record_fn = 'final_p_01_rlhf_output.json'\n",
    "suffix_kwargs = \"p_09_t_08_rlhf_output.json\"\n",
    "\n",
    "!rm alpaca_eval/final/*.json\n",
    "output_idx = 0\n",
    "for root_key in list(roots.keys()):#[output_idx+1:]:\n",
    "    root = roots[root_key]\n",
    "    record_path = root+f'/{record_fn}'\n",
    "    fn = record_path.split('/')[2].split('rl_')[1].split('_512_max_token')[0]\n",
    "    fn += suffix_kwargs\n",
    "    print(fn)\n",
    "    try:\n",
    "        records = load_records(record_path)\n",
    "        reward,res_len = deserialize(records,fn,root_key)\n",
    "        print(f'Mean of {len(reward)} reward for responses in {fn} is {np.mean(reward)}, median is {np.median(reward)} and standard deviation is {np.std(reward)}')\n",
    "        print(f'Mean of {len(res_len)} response is {np.mean(res_len)}, median is {np.median(res_len)} and standard deviation is {np.std(res_len)}')\n",
    "        print('==='*10)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print('==='*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpaca_eval make_leaderboard --leaderboard_path results/ld.csv --all_model_outputs 'alpaca_eval/crs_hp_tuning/*.json' --reference_outputs alpaca_eval/final/bs16_kl_001_clip_04p_09_t_08_rlhf_output.json --annotators_config 'alpaca_eval_gpt4_turbo_fn'\n",
      "===\n",
      "alpaca_eval make_leaderboard --leaderboard_path results/ld.csv --all_model_outputs 'alpaca_eval/crs_hp_tuning/*.json' --reference_outputs alpaca_eval/final/bs16_kl_002_clip_04p_09_t_08_rlhf_output.json --annotators_config 'alpaca_eval_gpt4_turbo_fn'\n",
      "===\n",
      "alpaca_eval make_leaderboard --leaderboard_path results/ld.csv --all_model_outputs 'alpaca_eval/crs_hp_tuning/*.json' --reference_outputs alpaca_eval/final/abs_quality_rw_075_bs16_kl_002_clip_04p_09_t_08_rlhf_output.json --annotators_config 'alpaca_eval_gpt4_turbo_fn'\n",
      "===\n",
      "alpaca_eval make_leaderboard --leaderboard_path results/ld.csv --all_model_outputs 'alpaca_eval/crs_hp_tuning/*.json' --reference_outputs alpaca_eval/final/f_crs_0625_bs16_kl_002_clip_04p_09_t_08_rlhf_output.json --annotators_config 'alpaca_eval_gpt4_turbo_fn'\n",
      "===\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"alpaca_eval --model_outputs 'alpaca_eval/LLama-2-7b-oasst-baseline_rl_abs_quality_rw_075_bs16_kl_002_clip_04_512_max_token_with_pad_eos_lr_141e5_logits/alpaca_final_p_01_run_1_rlhf_output.json' --reference_outputs 'alpaca_eval/LLama-2-7b-oasst-baseline_rl_bs16_kl_002_clip_04_512_max_token_with_pad_eos_lr_141e5/alpaca_final_p_01_run_1_rlhf_output.json' --annotators_config 'alpaca_eval_gpt4_turbo_fn'\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "r = ['output/rl/LLama-2-7b-oasst-baseline_rl_bs16_kl_001_clip_04_512_max_token_with_pad_eos_lr_141e5/eval_output',\n",
    "    \"output/rl/LLama-2-7b-oasst-baseline_rl_bs16_kl_002_clip_04_512_max_token_with_pad_eos_lr_141e5/eval_output\",\n",
    "    \"output/rl/LLama-2-7b-oasst-baseline_rl_abs_quality_rw_075_bs16_kl_002_clip_04_512_max_token_with_pad_eos_lr_141e5_logits/eval_output\",\n",
    "    \"output/rl/LLama-2-7b-oasst-baseline_rl_f_crs_0625_bs16_kl_002_clip_04_512_max_token_with_pad_eos_lr_141e5/eval_output\"]\n",
    "\n",
    "\n",
    "alpaca_path = all_path# [f\"alpaca_eval/{rr.split('/')[2]}/alpaca_{record_fn}\" for rr in r]\n",
    "\n",
    "# alpaca_command = \"alpaca_eval --model_outputs {0} --reference_outputs {1} --annotators_config 'alpaca_eval_gpt4_turbo_fn\"\n",
    "\n",
    "\n",
    "alpaca_command = \"\"\"alpaca_eval make_leaderboard --leaderboard_path results/ld.csv --all_model_outputs 'alpaca_eval/crs_hp_tuning/*.json' --reference_outputs {0} --annotators_config 'alpaca_eval_gpt4_turbo_fn'\"\"\"\n",
    "\n",
    "for i,p in enumerate(alpaca_path):\n",
    "    # mp = all_path[i+1:]\n",
    "    print(alpaca_command.format(p))\n",
    "    print('===')\n",
    "\n",
    "\n",
    "\n",
    "# alpaca_eval make_leaderboard --leaderboard_path results/vs0625.csv --all_model_outputs 'alpaca_eval/crs_hp_tuning/*.json' --reference_outputs alpaca_eval/LLama-2-7b-oasst-baseline_rl_crs_0625_bs16_kl_002_clip_04_512_max_token_with_pad_eos_lr_141e5/alpaca_tuning_p_09_t_08_rlhf_output.json --annotators_config 'alpaca_eval_gpt4_turbo_fn'\n",
    "\n",
    "model = 'alpaca_eval/LLama-2-7b-oasst-baseline_rl_abs_quality_rw_075_bs16_kl_002_clip_04_512_max_token_with_pad_eos_lr_141e5_logits/alpaca_final_p_01_run_1_rlhf_output.json'\n",
    "# 'output/rl/LLama-2-7b-oasst-baseline_rl_abs_quality_rw_075_bs16_kl_002_clip_04_512_max_token_with_pad_eos_lr_141e5_logits/eval_v1_double_check/final_p_01_run_1_rlhf_output.json'\n",
    "# 'alpaca_eval/final/bs16_kl_002_clip_04p_09_t_08_rlhf_output.json'\n",
    "# 'alpaca_eval/final/bs16_kl_001_clip_04p_09_t_08_rlhf_output.json'\n",
    "ref = 'alpaca_eval/LLama-2-7b-oasst-baseline_rl_bs16_kl_002_clip_04_512_max_token_with_pad_eos_lr_141e5/alpaca_final_p_01_run_1_rlhf_output.json'\n",
    "# 'output/rl/LLama-2-7b-oasst-baseline_rl_bs16_kl_002_clip_04_512_max_token_with_pad_eos_lr_141e5/eval_v1_double_check/final_p_01_run_1_rlhf_output.json'\n",
    "# alpaca_eval/final/abs_quality_rw_075_bs16_kl_002_clip_04p_09_t_08_rlhf_output.json'\n",
    "\n",
    "\n",
    "f\"alpaca_eval --model_outputs '{model}' --reference_outputs '{ref}' --annotators_config 'alpaca_eval_gpt4_turbo_fn'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"alpaca_eval --model_outputs 'alpaca_eval/LLama-2-7b-oasst-baseline_rl_bs16_kl_002_clip_04_512_max_token_with_pad_eos_lr_141e5/alpaca_final_p_09_t_08_rlhf_output.json' --reference_outputs 'alpaca_eval/LLama-2-7b-oasst-baseline_rl_abs_quality_rw_075_bs16_kl_002_clip_04_512_max_token_with_pad_eos_lr_141e5_logits/alpaca_final_p_09_t_08_rlhf_output.json' --annotators_config 'alpaca_eval_gpt4_turbo_fn\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ref = \"alpaca_eval/LLama-2-7b-oasst-baseline_rl_abs_quality_rw_075_bs16_kl_002_clip_04_512_max_token_with_pad_eos_lr_141e5_logits/alpaca_final_p_01_run_1_sft_output.json\"\n",
    "ref_path = 'alpaca_eval/LLama-2-7b-oasst-baseline_rl_abs_quality_rw_075_bs16_kl_002_clip_04_512_max_token_with_pad_eos_lr_141e5_logits'\n",
    "m_path = 'alpaca_eval/LLama-2-7b-oasst-baseline_rl_bs16_kl_002_clip_04_512_max_token_with_pad_eos_lr_141e5'\n",
    "\n",
    "fn = 'alpaca_final_p_09_t_08_rlhf_output.json'\n",
    "f1 = fn\n",
    "ref  = ref_path+'/alpaca_final_p_09_t_08_rlhf_output.json'\n",
    "model = m_path+'/alpaca_final_p_09_t_08_rlhf_output.json'\n",
    "\n",
    "# export OPENAI_API_KEY=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\n",
    "\n",
    "f\"alpaca_eval --model_outputs '{model}' --reference_outputs '{ref}' --annotators_config 'alpaca_eval_gpt4_turbo_fn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 1) (3355847018.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[41], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    alpaca_eval --model_outputs 'output/rl/LLama-2-7b-oasst-baseline_rl_bs16_kl_002_clip_04_512_max_token_with_pad_eos_lr_141e5/eval_output/final_p_01_run_1_rlhf_output.json' --reference_outputs 'output/rl/LLama-2-7b-oasst-baseline_rl_abs_quality_rw_075_bs16_kl_002_clip_04_512_max_token_with_pad_eos_lr_141e5_logits/eval_output/final_p_01_run_1_rlhf_output.json' --annotators_config 'alpaca_eval_gpt4_turbo_fn\"\u001b[0m\n\u001b[0m                                                                                                                                                                                                                                                                                                                                                                                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 1)\n"
     ]
    }
   ],
   "source": [
    "alpaca_eval --model_outputs 'output/rl/LLama-2-7b-oasst-baseline_rl_bs16_kl_002_clip_04_512_max_token_with_pad_eos_lr_141e5/eval_output/final_p_01_run_1_rlhf_output.json' --reference_outputs 'output/rl/LLama-2-7b-oasst-baseline_rl_abs_quality_rw_075_bs16_kl_002_clip_04_512_max_token_with_pad_eos_lr_141e5_logits/eval_output/final_p_01_run_1_rlhf_output.json' --annotators_config 'alpaca_eval_gpt4_turbo_fn\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation using direct API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are a helpful assistant, that makes a leaderboard of models based on the quality of their answers.\n",
      "<|im_end|>\n",
      "<|im_start|>user\n",
      "I want you to create a leaderboard of different of large-language models. To do so, I will give you the instructions (prompts) given to the models, and the responses of two models. To make a leaderboard, first make a list ranking the models based on which responses would be preferred by humans, then give the resulting list of JSON to `make_leaderboard`.\n",
      "\n",
      "Here is the prompt:\n",
      "{\n",
      "    \"instruction\": \"\"\"How do you become an author?\"\"\",\n",
      "}\n",
      "\n",
      "Here are the outputs of the models:\n",
      "[\n",
      "    {\n",
      "        \"model\": \"model_1\",\n",
      "        \"answer\": \"\"\"Becoming an author involves a combination of talent, hard work, and dedication. Here are some steps you can take to become an author:\n",
      "\n",
      "1. Write regularly: Practice your writing skills by writing every day, even if it's just for a few minutes. Write about anything that interests you, and don't be afraid to experiment with different genres and styles.\n",
      "\n",
      "2. Read widely: Reading widely will help you to develop your own writing style and to gain a deeper understanding of the craft of writing. Read books in your chosen genre, as well as books from other genres and from different time periods.\n",
      "\n",
      "3. Develop your ideas: Come up with ideas for stories, articles, or essays that you want to write. You can get ideas from your own life experiences, from current events, or from your own imagination.\n",
      "\n",
      "4. Revise and edit: Once you have written a draft, take the time to revise and edit it carefully. This will help you to identify areas that need improvement and to make your writing more cohesive and polished.\n",
      "\n",
      "5. Get feedback: Share your writing with others and ask for feedback. This can be from friends, family, or from writing groups or workshops. Use their feedback to improve your writing.\n",
      "\n",
      "6. Submit your work: Once you are confident in your writing, start submitting it to publishers, magazines, or websites that accept unsolicited submissions. You may need to submit many pieces before you are published, but perseverance is key.\n",
      "\n",
      "7. Promote your work: Once your work is published, promote it through social media, websites, and other channels. This will help you to build a following and to sell more copies of your book.\n",
      "\n",
      "Remember, becoming an author is a long-term process that requires dedication and hard work. Don't be discouraged by rejections or setbacks, and keep writing and improving your craft.\"\"\"\n",
      "    },\n",
      "    {\n",
      "        \"model\": \"model_2\",\n",
      "        \"answer\": \"\"\"Becoming an author involves a combination of hard work, dedication, and persistence. Here are some steps you can take to become an author:\n",
      "\n",
      "Write regularly: The key to becoming an author is to write regularly. Set aside time each day or each week to work on your writing projects. You can start by writing for a few minutes a day and gradually increase the amount of time you spend writing.\n",
      "\n",
      "Study the craft of writing: Learn the basics of grammar, punctuation, and syntax. Read widely in your chosen genre to learn from established authors. Take writing workshops, attend conferences, and join writing groups to get feedback on your work and learn from other writers.\n",
      "\n",
      "Develop a writing routine: Establish a routine for writing, such as setting aside a specific time each day or each week to work on your writing. This can help you build discipline and make writing a priority in your life.\n",
      "\n",
      "Write what you love: Write about topics and themes that you are passionate about. If you enjoy what you are writing, it will show in your work and it will be easier to maintain your motivation.\n",
      "\n",
      "Develop a thick skin: Writing is subjective, and not everyone will love your work. Learn to develop a thick skin and ignore negative feedback. Focus on improving your craft and creating work that you are proud of.\n",
      "\n",
      "Publish your work: Once you have written a manuscript, consider self-publishing or traditional publishing. Self-publishing allows you to control the process and get your work out there quickly, while traditional publishing can provide more recognition and support.\n",
      "\n",
      "Remember, becoming an author is a process that takes time and effort. Don't be discouraged by rejection or setbacks, and keep writing and improving your craft.\"\"\"\n",
      "    }\n",
      "]\n",
      "\n",
      "Now make the leaderboard by ranking the models by the quality of their answers, so that the model with rank 1 has the best output.\n",
      "<|im_end|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "instruction = \"I like to host guests at my home from time to time, and I am gathering  recipes of different dishes and drinks to keep things interesting. I am interested in trying some Danish dishes. Can you give me a recipe for Flæskesteg?\"\n",
    "\n",
    "#rlhf\n",
    "output_1 = \"\"\"Certainly! Flæskesteg is a traditional Danish roast pork dish that is typically served with potatoes and red cabbage. Here's a recipe for you to try:\\n\\nIngredients:\\n\\n    1.5 kg (3.3 lbs) boneless pork shoulder, trimmed of fat\\n    2 tbsp oil\\n    1 large onion, chopped\\n    1 carrot, chopped\\n    1 celery stalk, chopped\\n    1 tsp ground allspice\\n    1 tsp ground black pepper\\n    1 tsp salt\\n    3 cloves garlic, minced\\n    2 bay leaves\\n    1 tbsp vinegar\\n    2 tbsp beer\\n    1 tbsp molasses\\n    1 tbsp Worcestershire sauce\\n    Potatoes, peeled and cut into wedges\\n    Red cabbage, shredded\\n\\nInstructions:\\n\\n    Heat the oil in a large Dutch oven or roasting pan over medium heat. Add the onion, carrot, celery, and allspice and cook until softened, about 5 minutes.\\n\\n    Add the pork to the pan and cook, breaking it up with a spoon, until browned, about 10 minutes.\\n\\n    Add the garlic, bay leaves, vinegar, beer, molasses, Worcestershire sauce, and salt and pepper to taste. Bring to a boil, then reduce the heat to low and simmer, covered, for 1 hour.\\n\\n    Transfer the pork to a plate and set aside to rest for 10 minutes.\\n\\n    Add the potatoes to the pan and cook, stirring occasionally, until tender, about 20 minutes.\\n\\n    Add the red cabbage to the pan and cook, stirring occasionally, until heated through, about 5 minutes.\\n\\n    Slice the pork against the grain into thin slices. Serve the pork with the potatoes and cabbage, and enjoy!\\n\\nThis recipe should serve 4-6 people.\"\"\"\n",
    "output_2 = \"\"\"Flæskesteg is a classic Danish roast pork dish that is usually served as a main course during special occasions or holidays. Here's a recipe that you can try at home:\\n\\nIngredients:\\n\\n    2 pork loins (about 3-4 pounds each)\\n    2 tablespoons butter\\n    2 teaspoons salt\\n    1 teaspoon black pepper\\n    2 tablespoons brown sugar\\n    1/2 cup beer\\n    2 tablespoons cider vinegar\\n    1 large onion, sliced\\n    2 cloves garlic, minced\\n    1 tablespoon all-purpose flour\\n    1/2 cup heavy cream\\n    1/4 cup unsalted butter\\n    1/2 cup breadcrumbs\\n    1/4 cup chopped parsley\\n\\nInstructions:\\n\\n    Preheat the oven to 325°F (160°C).\\n    Place the pork loins in a large roasting pan and rub them with the butter.\\n    Sprinkle them with the salt, pepper, and brown sugar.\\n    Roast the pork for 1 hour, or until it is golden brown and slightly pink in the center.\\n    Remove the pork from the oven and cover it with foil.\\n    In a small saucepan, combine the beer, vinegar, onion, and garlic. Bring to a boil, reduce the heat to low, and simmer for 10 minutes.\\n    Remove the pan from the heat and let it cool for a few minutes.\\n    Whisk the flour into the cooled beer mixture until it forms a thick paste.\\n    In a separate saucepan, whisk the heavy cream until it thickens slightly.\\n    Pour the cream into the beer mixture and stir until well combined.\\n    Bring the mixture back to a simmer and cook for 2-3 minutes, or until it thickens slightly.\\n    Remove the pan from the heat and let it cool for a few minutes.\\n    Stir the butter into the sauce until it melts and combines with the sauce.\\n    Remove the pork from the foil and pour the sau\"\"\"\n",
    "\n",
    "instruction=\"How do you become an author?\"\n",
    "output_1=\"Becoming an author involves a combination of talent, hard work, and dedication. Here are some steps you can take to become an author:\\n\\n1. Write regularly: Practice your writing skills by writing every day, even if it's just for a few minutes. Write about anything that interests you, and don't be afraid to experiment with different genres and styles.\\n\\n2. Read widely: Reading widely will help you to develop your own writing style and to gain a deeper understanding of the craft of writing. Read books in your chosen genre, as well as books from other genres and from different time periods.\\n\\n3. Develop your ideas: Come up with ideas for stories, articles, or essays that you want to write. You can get ideas from your own life experiences, from current events, or from your own imagination.\\n\\n4. Revise and edit: Once you have written a draft, take the time to revise and edit it carefully. This will help you to identify areas that need improvement and to make your writing more cohesive and polished.\\n\\n5. Get feedback: Share your writing with others and ask for feedback. This can be from friends, family, or from writing groups or workshops. Use their feedback to improve your writing.\\n\\n6. Submit your work: Once you are confident in your writing, start submitting it to publishers, magazines, or websites that accept unsolicited submissions. You may need to submit many pieces before you are published, but perseverance is key.\\n\\n7. Promote your work: Once your work is published, promote it through social media, websites, and other channels. This will help you to build a following and to sell more copies of your book.\\n\\nRemember, becoming an author is a long-term process that requires dedication and hard work. Don't be discouraged by rejections or setbacks, and keep writing and improving your craft.\"\n",
    "#rlhf\n",
    "output_2=\"Becoming an author involves a combination of hard work, dedication, and persistence. Here are some steps you can take to become an author:\\n\\nWrite regularly: The key to becoming an author is to write regularly. Set aside time each day or each week to work on your writing projects. You can start by writing for a few minutes a day and gradually increase the amount of time you spend writing.\\n\\nStudy the craft of writing: Learn the basics of grammar, punctuation, and syntax. Read widely in your chosen genre to learn from established authors. Take writing workshops, attend conferences, and join writing groups to get feedback on your work and learn from other writers.\\n\\nDevelop a writing routine: Establish a routine for writing, such as setting aside a specific time each day or each week to work on your writing. This can help you build discipline and make writing a priority in your life.\\n\\nWrite what you love: Write about topics and themes that you are passionate about. If you enjoy what you are writing, it will show in your work and it will be easier to maintain your motivation.\\n\\nDevelop a thick skin: Writing is subjective, and not everyone will love your work. Learn to develop a thick skin and ignore negative feedback. Focus on improving your craft and creating work that you are proud of.\\n\\nPublish your work: Once you have written a manuscript, consider self-publishing or traditional publishing. Self-publishing allows you to control the process and get your work out there quickly, while traditional publishing can provide more recognition and support.\\n\\nRemember, becoming an author is a process that takes time and effort. Don't be discouraged by rejection or setbacks, and keep writing and improving your craft.\"\n",
    "input_prompt = f\"\"\"<|im_start|>system\n",
    "You are a helpful assistant, that makes a leaderboard of models based on the quality of their answers.\n",
    "<|im_end|>\n",
    "<|im_start|>user\n",
    "I want you to create a leaderboard of different of large-language models. To do so, I will give you the instructions (prompts) given to the models, and the responses of two models. To make a leaderboard, first make a list ranking the models based on which responses would be preferred by humans, then give the resulting list of JSON to `make_leaderboard`.\n",
    "\n",
    "Here is the prompt:\n",
    "{{\n",
    "    \"instruction\": \\\"\"\"{instruction}\\\"\"\",\n",
    "}}\n",
    "\n",
    "Here are the outputs of the models:\n",
    "[\n",
    "    {{\n",
    "        \"model\": \"model_1\",\n",
    "        \"answer\": \\\"\"\"{output_1}\\\"\"\"\n",
    "    }},\n",
    "    {{\n",
    "        \"model\": \"model_2\",\n",
    "        \"answer\": \\\"\"\"{output_2}\\\"\"\"\n",
    "    }}\n",
    "]\n",
    "\n",
    "Now make the leaderboard by ranking the models by the quality of their answers, so that the model with rank 1 has the best output.\n",
    "<|im_end|>\n",
    "\"\"\"\n",
    "\n",
    "print(input_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from openai import OpenAI\n",
    "import openai\n",
    "\n",
    "openai_api_keys = \"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\"\n",
    "base_url = openai.base_url\n",
    "client = OpenAI(base_url=base_url,api_key=openai_api_keys)\n",
    "# OPENAI_API_KEY=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\n",
    "\n",
    "client_kwargs = {\n",
    "    \"model\": \"gpt-4-1106-preview\",\n",
    "    \"max_tokens\": 100,\n",
    "    \"temperature\": 0,\n",
    "    \"top_p\":1.0,\n",
    "    \"function_call\": {\n",
    "      \"name\": \"make_leaderboard\"\n",
    "    },\n",
    "    \"functions\": [\n",
    "      {\n",
    "        \"name\": \"make_leaderboard\",\n",
    "        \"description\": \"Make a leaderboard of models given a list of the models ordered by the preference of their outputs.\",\n",
    "        \"parameters\": {\n",
    "          \"type\": \"object\",\n",
    "          \"properties\": {\n",
    "            \"ordered_models\": {\n",
    "              \"type\": \"array\",\n",
    "              \"description\": \"A list of models ordered by the preference of their outputs\",\n",
    "              \"items\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                  \"model\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The name of the model\"\n",
    "                  },\n",
    "                  \"rank\": {\n",
    "                    \"type\": \"number\",\n",
    "                    \"description\": \"Order of preference of the model, 1 has the best output\"\n",
    "                  }\n",
    "                }\n",
    "              }\n",
    "            }\n",
    "          }\n",
    "        },\n",
    "        \"required\": [\"ordered_models\"]\n",
    "      }\n",
    "    ]\n",
    "  }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "        messages=[{\"role\": \"user\", \"content\":input_prompt}],\n",
    "        **client_kwargs\n",
    "    )\n",
    "print(response.choices[0].message.function_call.arguments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "a = \"Lets try to fool vocabultary. Mean giahslflal tripallav vakunama tirakutti lafuddu\"\n",
    "enc = tiktoken.encoding_for_model(client_kwargs[\"model\"])\n",
    "assert enc.decode(enc.encode(a)) == a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpaca_eval --model_outputs 'alpaca_eval/LLama-2-7b-oasst-baseline_rl_bs16_kl_002_clip_04_512_max_token_with_pad_eos_lr_141e5/alpaca_final_p_01_run_1_rlhf_output.json' --reference_outputs 'alpaca_eval/LLama-2-7b-oasst-baseline_rl_abs_quality_rw_075_bs16_kl_002_clip_04_512_max_token_with_pad_eos_lr_141e5_logits/alpaca_final_p_01_run_1_rlhf_output.json' --annotators_config 'alpaca_eval_gpt4_turbo_fn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_df = pd.read_json(ref)\n",
    "model_df = pd.read_json(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192.48"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_df.output.str.split().apply(lambda x: len(x)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruction</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I like to host guests at my home from time to ...</td>\n",
       "      <td>Sure! Flæskesteg (literally meaning \"bacon roa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How do you become an author?</td>\n",
       "      <td>Becoming an author involves a combination of h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Can you help me figure out how to sew a button...</td>\n",
       "      <td>Sewing a button on a shirt is a simple process...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How do I get better at aiming with my slingshot?</td>\n",
       "      <td>Improving one's aim with a slingshot involves ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Best way to defrost a refrigerator freezer?</td>\n",
       "      <td>As a language model, I don't have the ability ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>When was the LEGO group founded? and when did ...</td>\n",
       "      <td>The LEGO Group was founded in 1932 by Ole Kirk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Nómbrame todos los jugadores que han ganado el...</td>\n",
       "      <td>Los jugadores que han ganado el Premio al Mejo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>What is the average length of a female finger?...</td>\n",
       "      <td>The average length of a female finger is aroun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Hi, I am trying to plan a camping holiday with...</td>\n",
       "      <td>Here are some commonly needed items for campin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>How does metabolism work?</td>\n",
       "      <td>Metabolism is the series of biochemical proces...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          instruction                                             output\n",
       "0   I like to host guests at my home from time to ...  Sure! Flæskesteg (literally meaning \"bacon roa...\n",
       "1                        How do you become an author?  Becoming an author involves a combination of h...\n",
       "2   Can you help me figure out how to sew a button...  Sewing a button on a shirt is a simple process...\n",
       "3    How do I get better at aiming with my slingshot?  Improving one's aim with a slingshot involves ...\n",
       "4         Best way to defrost a refrigerator freezer?  As a language model, I don't have the ability ...\n",
       "..                                                ...                                                ...\n",
       "95  When was the LEGO group founded? and when did ...  The LEGO Group was founded in 1932 by Ole Kirk...\n",
       "96  Nómbrame todos los jugadores que han ganado el...  Los jugadores que han ganado el Premio al Mejo...\n",
       "97  What is the average length of a female finger?...  The average length of a female finger is aroun...\n",
       "98  Hi, I am trying to plan a camping holiday with...  Here are some commonly needed items for campin...\n",
       "99                          How does metabolism work?  Metabolism is the series of biochemical proces...\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(ref2_df.response == ref_df.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruction</th>\n",
       "      <th>output_1</th>\n",
       "      <th>output_2</th>\n",
       "      <th>annotator</th>\n",
       "      <th>preference</th>\n",
       "      <th>price_per_example</th>\n",
       "      <th>time_per_example</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I like to host guests at my home from time to ...</td>\n",
       "      <td>Here's a recipe for Danish roast pork (Flæskes...</td>\n",
       "      <td>Certainly! Flæskesteg is a classic Danish dish...</td>\n",
       "      <td>alpaca_eval_gpt4_turbo_fn</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01058</td>\n",
       "      <td>0.470657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How do you become an author?</td>\n",
       "      <td>To become an author, consider the following st...</td>\n",
       "      <td>Becoming an author involves a combination of t...</td>\n",
       "      <td>alpaca_eval_gpt4_turbo_fn</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00820</td>\n",
       "      <td>0.470657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Can you help me figure out how to sew a button...</td>\n",
       "      <td>Sure, here's a step-by-step guide on how to se...</td>\n",
       "      <td>Certainly! Here's a step-by-step guide to teac...</td>\n",
       "      <td>alpaca_eval_gpt4_turbo_fn</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00717</td>\n",
       "      <td>0.470657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How do I get better at aiming with my slingshot?</td>\n",
       "      <td>Improving your aim with a slingshot takes prac...</td>\n",
       "      <td>There are several things you can do to improve...</td>\n",
       "      <td>alpaca_eval_gpt4_turbo_fn</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00802</td>\n",
       "      <td>0.470657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Best way to defrost a refrigerator freezer?</td>\n",
       "      <td>The best way to defrost a refrigerator freezer...</td>\n",
       "      <td>The best way to defrost a refrigerator freezer...</td>\n",
       "      <td>alpaca_eval_gpt4_turbo_fn</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00559</td>\n",
       "      <td>0.470657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>When was the LEGO group founded? and when did ...</td>\n",
       "      <td>The LEGO Group, the Danish manufacturer of pla...</td>\n",
       "      <td>The LEGO Group was founded in 1932 by Ole Kirk...</td>\n",
       "      <td>alpaca_eval_gpt4_turbo_fn</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00585</td>\n",
       "      <td>0.470657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Nómbrame todos los jugadores que han ganado el...</td>\n",
       "      <td>Aquí está un listado de todos los jugadores qu...</td>\n",
       "      <td>A continuación, te muestro una lista de los ga...</td>\n",
       "      <td>alpaca_eval_gpt4_turbo_fn</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01055</td>\n",
       "      <td>0.470657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>What is the average length of a female finger?...</td>\n",
       "      <td>The average length of a female finger is appro...</td>\n",
       "      <td>The average length of a female finger is aroun...</td>\n",
       "      <td>alpaca_eval_gpt4_turbo_fn</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00617</td>\n",
       "      <td>0.470657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Hi, I am trying to plan a camping holiday with...</td>\n",
       "      <td>That depends on how long your camping trip wil...</td>\n",
       "      <td>Here are some essential items to consider when...</td>\n",
       "      <td>alpaca_eval_gpt4_turbo_fn</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00911</td>\n",
       "      <td>0.470657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>How does metabolism work?</td>\n",
       "      <td>Metabolism refers to the biochemical processes...</td>\n",
       "      <td>Metabolism is the process by which the body co...</td>\n",
       "      <td>alpaca_eval_gpt4_turbo_fn</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00790</td>\n",
       "      <td>0.470657</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          instruction  ... time_per_example\n",
       "0   I like to host guests at my home from time to ...  ...         0.470657\n",
       "1                        How do you become an author?  ...         0.470657\n",
       "2   Can you help me figure out how to sew a button...  ...         0.470657\n",
       "3    How do I get better at aiming with my slingshot?  ...         0.470657\n",
       "4         Best way to defrost a refrigerator freezer?  ...         0.470657\n",
       "..                                                ...  ...              ...\n",
       "95  When was the LEGO group founded? and when did ...  ...         0.470657\n",
       "96  Nómbrame todos los jugadores que han ganado el...  ...         0.470657\n",
       "97  What is the average length of a female finger?...  ...         0.470657\n",
       "98  Hi, I am trying to plan a camping holiday with...  ...         0.470657\n",
       "99                          How does metabolism work?  ...         0.470657\n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anno_df = pd.read_json('alpaca_eval/LLama-2-7b-oasst-baseline_rl_bs16_kl_002_clip_04_512_max_token_with_pad_eos_lr_141e5/annotation_alpaca_eval_gpt4_turbo_fn.json')\n",
    "\n",
    "anno_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(ref_df.output == anno_df.output_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "preference\n",
       "1    53\n",
       "2    47\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anno_df.preference.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180.4"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anno_df.output_1.str.split().apply(lambda x: len(x)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136.82"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anno_df.output_2.str.split().apply(lambda x: len(x)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1072772/881330586.py:5: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_df = pd.concat(dfs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>win_rate</th>\n",
       "      <th>standard_error</th>\n",
       "      <th>n_wins</th>\n",
       "      <th>n_wins_base</th>\n",
       "      <th>n_draws</th>\n",
       "      <th>n_total</th>\n",
       "      <th>mode</th>\n",
       "      <th>avg_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>625</td>\n",
       "      <td>62.0</td>\n",
       "      <td>6.934092</td>\n",
       "      <td>31</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>verified</td>\n",
       "      <td>1242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>46.0</td>\n",
       "      <td>7.119963</td>\n",
       "      <td>23</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>verified</td>\n",
       "      <td>1277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75</td>\n",
       "      <td>46.0</td>\n",
       "      <td>7.119963</td>\n",
       "      <td>23</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>verified</td>\n",
       "      <td>1099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>625</td>\n",
       "      <td>50.0</td>\n",
       "      <td>7.142857</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>verified</td>\n",
       "      <td>1242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75</td>\n",
       "      <td>44.0</td>\n",
       "      <td>7.091242</td>\n",
       "      <td>22</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>verified</td>\n",
       "      <td>1099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75</td>\n",
       "      <td>42.0</td>\n",
       "      <td>7.050836</td>\n",
       "      <td>21</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>verified</td>\n",
       "      <td>1099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>625</td>\n",
       "      <td>64.0</td>\n",
       "      <td>6.857143</td>\n",
       "      <td>32</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>verified</td>\n",
       "      <td>1242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75</td>\n",
       "      <td>46.0</td>\n",
       "      <td>7.119963</td>\n",
       "      <td>23</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>verified</td>\n",
       "      <td>1099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>42.0</td>\n",
       "      <td>7.050836</td>\n",
       "      <td>21</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>verified</td>\n",
       "      <td>1277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>375</td>\n",
       "      <td>32.0</td>\n",
       "      <td>6.663945</td>\n",
       "      <td>16</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>verified</td>\n",
       "      <td>1316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0  win_rate  standard_error n_wins n_wins_base n_draws n_total  \\\n",
       "0        625      62.0        6.934092     31          19       0      50   \n",
       "1          5      46.0        7.119963     23          27       0      50   \n",
       "2         75      46.0        7.119963     23          27       0      50   \n",
       "0        625      50.0        7.142857     25          25       0      50   \n",
       "1         75      44.0        7.091242     22          28       0      50   \n",
       "0         75      42.0        7.050836     21          29       0      50   \n",
       "0        625      64.0        6.857143     32          18       0      50   \n",
       "1         75      46.0        7.119963     23          27       0      50   \n",
       "2          5      42.0        7.050836     21          29       0      50   \n",
       "3        375      32.0        6.663945     16          34       0      50   \n",
       "\n",
       "       mode avg_length  \n",
       "0  verified       1242  \n",
       "1  verified       1277  \n",
       "2  verified       1099  \n",
       "0  verified       1242  \n",
       "1  verified       1099  \n",
       "0  verified       1099  \n",
       "0  verified       1242  \n",
       "1  verified       1099  \n",
       "2  verified       1277  \n",
       "3  verified       1316  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = []\n",
    "for dfpath in glob(\"results/*.csv\"):\n",
    "    dfs.append(pd.read_csv(dfpath))\n",
    "\n",
    "all_df = pd.concat(dfs)\n",
    "\n",
    "all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1072772/3409309043.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mopponent\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Model'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Opponent'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mopponent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;31m# Find the complementary win rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Model'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mopponent\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Opponent'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0mwin_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Model'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mopponent\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Opponent'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Win Rate'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                 \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'Model'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Opponent'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mopponent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Win Rate'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mwin_rate\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Filter out the models not in the specified list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mspecified_models\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'025'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'375'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'625'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'75'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6200\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6201\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6202\u001b[0m         ):\n\u001b[1;32m   6203\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6204\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'append'"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_p310_ppo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
