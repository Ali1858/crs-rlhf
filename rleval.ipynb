{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reward score at each step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading records for file:output/rl/LLama-2-7b-oasst-baseline_rl_bs16_kl_002_clip_04_512_max_token_with_pad_eos_lr_141e5/eval_output/responses_rewards_step_75.json\n",
      "reward for step 75 from active model is :(0.8056396484375, 0.8193853493887262) and ref model is: (0.47811279296875, 1.1169018467594098)\n",
      "******************************\n",
      "loading records for file:output/rl/LLama-2-7b-oasst-baseline_rl_bs16_kl_002_clip_04_512_max_token_with_pad_eos_lr_141e5/eval_output/responses_rewards_step_150.json\n",
      "reward for step 150 from active model is :(0.810809326171875, 0.6753196021763054) and ref model is: (1.1474609375, 1.095375901589811)\n",
      "******************************\n",
      "loading records for file:output/rl/LLama-2-7b-oasst-baseline_rl_bs16_kl_002_clip_04_512_max_token_with_pad_eos_lr_141e5/eval_output/responses_rewards_step_225.json\n",
      "reward for step 225 from active model is :(1.18369140625, 0.7941681548908883) and ref model is: (0.486181640625, 1.570982226373815)\n",
      "******************************\n",
      "loading records for file:output/rl/LLama-2-7b-oasst-baseline_rl_bs16_kl_002_clip_04_512_max_token_with_pad_eos_lr_141e5/eval_output/responses_rewards_step_300.json\n",
      "reward for step 300 from active model is :(1.054736328125, 0.9941190993820893) and ref model is: (0.514019775390625, 0.9368023462233588)\n",
      "******************************\n",
      "loading records for file:output/rl/LLama-2-7b-oasst-baseline_rl_bs16_kl_002_clip_04_512_max_token_with_pad_eos_lr_141e5/eval_output/responses_rewards_step_375.json\n",
      "reward for step 375 from active model is :(1.91484375, 0.7347443386403617) and ref model is: (1.24248046875, 1.0611567409772737)\n",
      "******************************\n",
      "loading records for file:output/rl/LLama-2-7b-oasst-baseline_rl_bs16_kl_002_clip_04_512_max_token_with_pad_eos_lr_141e5/eval_output/responses_rewards_step_450.json\n",
      "reward for step 450 from active model is :(1.630859375, 1.0928655045275828) and ref model is: (0.55439453125, 1.4205350863008428)\n",
      "******************************\n",
      "loading records for file:output/rl/LLama-2-7b-oasst-baseline_rl_bs16_kl_002_clip_04_512_max_token_with_pad_eos_lr_141e5/eval_output/responses_rewards_step_525.json\n",
      "reward for step 525 from active model is :(1.13447265625, 0.9600790565443367) and ref model is: (0.93681640625, 0.9680537570576052)\n",
      "******************************\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "def save_json(data, file_path):\n",
    "    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "    with open(file_path, 'w', encoding='utf-8') as file:\n",
    "        json.dump(data, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "\n",
    "def load_records(record_path):\n",
    "    print(f'loading records for file:{record_path}')\n",
    "    with open(record_path,'r') as f:\n",
    "        records = json.load(f)\n",
    "    return records\n",
    "\n",
    "def deserialize(records,step):\n",
    "    reward = []\n",
    "    ref_reward = []\n",
    "    model_output = []\n",
    "    reference_output = []\n",
    "    for record in records:\n",
    "        reward.append(record[\"reward\"])\n",
    "        ref_reward.append(record[\"ref_reward\"])\n",
    "\n",
    "        model_output.append({'instruction':record[\"query\"],'output':record[\"response\"]})\n",
    "        reference_output.append({'instruction':record[\"query\"],'output':record[\"ref_response\"]})\n",
    "\n",
    "    # save_json(model_output,f'{root}/clean_data/output_{step}.json')\n",
    "    # save_json(model_output,f'{root}/clean_data/reference_{step}.json')\n",
    "\n",
    "\n",
    "    return reward, ref_reward\n",
    "\n",
    "root = \"output/rl/LLama-2-7b-oasst-baseline_rl_bs16_kl_001_clip_04_512_max_token_with_pad_eos_lr_141e5/eval_output\"\n",
    "# root = \"output/rl/LLama-2-7b-oasst-baseline_rl_bs16_kl_015_clip_035_512_max_token_with_pad_eos_lr_741e5/eval_output\"\n",
    "# root = \"output/rl/LLama-2-7b-oasst-baseline_rl_bs16_kl_001_clip_04_512_max_token_with_pad_eos_lr_141e5_10p_data_rank/eval_output\"\n",
    "root = \"output/rl/LLama-2-7b-oasst-baseline_rl_bs16_kl_002_clip_04_512_max_token_with_pad_eos_lr_141e5/eval_output\"\n",
    "# root = \"output/rl/LLama-2-7b-oasst-baseline_rl_abs_quality_rw_075_bs16_kl_002_clip_04_512_max_token_with_pad_eos_lr_141e5/eval_output\"\n",
    "# root = \"output/rl/LLama-2-7b-oasst-baseline_rl_abs_quality_rw_075_bs16_kl_002_clip_04_512_max_token_with_pad_eos_lr_141e5_r32_alpha_64/eval_output\"\n",
    "# root = \"output/rl/LLama-2-7b-oasst-baseline_rl_abs_quality_rw_075_bs16_kl_002_clip_04_512_max_token_with_pad_eos_lr_141e5_logits/eval_output\"\n",
    "# root = \"output/rl/LLama-2-7b-oasst-baseline_rl_abs_quality_rw_075_bs16_kl_002_clip_04_512_max_token_with_pad_eos_lr_141e5_logits_adjusted/eval_output\"\n",
    "for step in [75,150,225,300,375,450,525]:\n",
    "    try:\n",
    "        record_path = f\"{root}/responses_rewards_step_{step}.json\"\n",
    "        records = load_records(record_path)\n",
    "        reward,ref_reward = deserialize(records,step)\n",
    "        print(f'reward for step {step} from active model is :{np.mean(reward),np.std(reward)} and ref model is: {np.mean(ref_reward),np.std(ref_reward)}')\n",
    "        print('***'*10)\n",
    "    except Exception as e:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpaca_eval --model_outputs 'alpaca_eval/clean_data/output_150.json' --reference_outputs 'alpaca_eval/clean_data/output_300.json' --annotators_config 'alpaca_eval_gpt4_turbo_fn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data for alpaca_eval RLHF vs SFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading records for a file at path: output/rl/LLama-2-7b-oasst-baseline_rl_abs_quality_rw_075_bs16_kl_002_clip_04_512_max_token_with_pad_eos_lr_141e5_logits_adjusted/eval_output/tuning_p_01_run_1_rlhf_output.json\n",
      "Mean of 50 reward for responses in tuning_p_01_run_1_rlhf_output.json is 0.71272705078125, median is 0.779296875 and standard deviation is 0.6236641596637422\n",
      "Mean of 50 response is 166.68, median is 170.5 and standard deviation is 68.18693129918665\n",
      "==============================\n",
      "loading records for a file at path: output/rl/LLama-2-7b-oasst-baseline_rl_abs_quality_rw_075_bs16_kl_002_clip_04_512_max_token_with_pad_eos_lr_141e5_logits_adjusted/eval_output/tuning_p_09_t_08_rlhf_output.json\n",
      "Mean of 50 reward for responses in tuning_p_09_t_08_rlhf_output.json is 0.8115625, median is 0.833984375 and standard deviation is 0.6419359728297602\n",
      "Mean of 50 response is 175.96, median is 191.0 and standard deviation is 78.35788664837764\n",
      "==============================\n",
      "loading records for a file at path: output/rl/LLama-2-7b-oasst-baseline_rl_abs_quality_rw_075_bs16_kl_002_clip_04_512_max_token_with_pad_eos_lr_141e5_logits_adjusted/eval_output/tuning_p_01_run_1_sft_output.json\n",
      "Mean of 50 reward for responses in tuning_p_01_run_1_sft_output.json is 0.46796630859375, median is 0.560546875 and standard deviation is 0.6650530915157199\n",
      "Mean of 50 response is 142.92, median is 132.0 and standard deviation is 91.91253233373564\n",
      "==============================\n",
      "loading records for a file at path: output/rl/LLama-2-7b-oasst-baseline_rl_abs_quality_rw_075_bs16_kl_002_clip_04_512_max_token_with_pad_eos_lr_141e5_logits_adjusted/eval_output/tuning_p_09_t_08_sft_output.json\n",
      "Mean of 50 reward for responses in tuning_p_09_t_08_sft_output.json is 0.51615234375, median is 0.71484375 and standard deviation is 0.8687497740820721\n",
      "Mean of 50 response is 179.94, median is 173.5 and standard deviation is 94.7460627150279\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import json\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "\n",
    "def save_json(data, file_path):\n",
    "    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "    with open(file_path, 'w', encoding='utf-8') as file:\n",
    "        json.dump(data, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "\n",
    "def load_records(record_path):\n",
    "    print(f'loading records for a file at path: {record_path}')\n",
    "    with open(record_path,'r') as f:\n",
    "        records = json.load(f)\n",
    "    return records\n",
    "\n",
    "\n",
    "def deserialize(records,suffix):\n",
    "    reward = []\n",
    "    res_len = []\n",
    "    model_output = []\n",
    "    for record in records:\n",
    "        reward.append(record[\"reward\"])\n",
    "        res_len.append(len(record[\"response\"].split()))\n",
    "        q = record[\"query\"]\n",
    "        q = q.split(\"<|im_start|>user\\n\")[-1].split(\"<|im_end|>\\n<|im_start|>assistant\\n\")[0]\n",
    "        model_output.append({'instruction':q,'output':record[\"response\"]})\n",
    "    save_json(model_output,f'{save_dir}/alpaca_{suffix}')\n",
    "    return reward,res_len\n",
    "\n",
    "\n",
    "root = \"output/rl/LLama-2-7b-oasst-baseline_rl_bs16_kl_001_clip_04_512_max_token_with_pad_eos_lr_141e5/eval_output\"\n",
    "# root = \"output/rl/LLama-2-7b-oasst-baseline_rl_bs16_kl_002_clip_04_512_max_token_with_pad_eos_lr_141e5/eval_output\"\n",
    "root = \"output/rl/LLama-2-7b-oasst-baseline_rl_abs_quality_rw_075_bs16_kl_002_clip_04_512_max_token_with_pad_eos_lr_141e5_logits_adjusted/eval_output\"\n",
    " #_adjusted \"\n",
    "save_dir = f\"alpaca_eval/{root.split('/')[2]}\"\n",
    "\n",
    "rlhf_output = list(glob(root+'/*_rlhf_output.json'))\n",
    "sft_output = list(glob(root+'/*_sft_output.json'))\n",
    "predicted_files = {\"rlhf\":rlhf_output,\n",
    "         \"sft\":sft_output}\n",
    "for type, paths in predicted_files.items():\n",
    "    for record_path in paths:\n",
    "        fn = record_path.split('/')[-1]\n",
    "        try:\n",
    "            records = load_records(record_path)\n",
    "            reward,res_len = deserialize(records,fn)\n",
    "            print(f'Mean of {len(reward)} reward for responses in {fn} is {np.mean(reward)}, median is {np.median(reward)} and standard deviation is {np.std(reward)}')\n",
    "            print(f'Mean of {len(res_len)} response is {np.mean(res_len)}, median is {np.median(res_len)} and standard deviation is {np.std(res_len)}')\n",
    "            print('==='*10)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print('==='*10)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpaca_eval --model_outputs 'alpaca_eval/LLama-2-7b-oasst-baseline_rl_abs_quality_rw_075_bs16_kl_002_clip_04_512_max_token_with_pad_eos_lr_141e5_logits/alpaca_tuning_p_01_run_1_rlhf_output.json' --reference_outputs 'alpaca_eval/LLama-2-7b-oasst-baseline_rl_abs_quality_rw_075_bs16_kl_002_clip_04_512_max_token_with_pad_eos_lr_141e5_logits_adjusted/alpaca_tuning_p_01_run_1_rlhf_output.json' --annotators_config 'alpaca_eval_gpt4_turbo_fn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation using direct API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are a helpful assistant, that makes a leaderboard of models based on the quality of their answers.\n",
      "<|im_end|>\n",
      "<|im_start|>user\n",
      "I want you to create a leaderboard of different of large-language models. To do so, I will give you the instructions (prompts) given to the models, and the responses of two models. To make a leaderboard, first make a list ranking the models based on which responses would be preferred by humans, then give the resulting list of JSON to `make_leaderboard`.\n",
      "\n",
      "Here is the prompt:\n",
      "{\n",
      "    \"instruction\": \"\"\"How do you become an author?\"\"\",\n",
      "}\n",
      "\n",
      "Here are the outputs of the models:\n",
      "[\n",
      "    {\n",
      "        \"model\": \"model_1\",\n",
      "        \"answer\": \"\"\"Becoming an author involves a combination of talent, hard work, and dedication. Here are some steps you can take to become an author:\n",
      "\n",
      "1. Write regularly: Practice your writing skills by writing every day, even if it's just for a few minutes. Write about anything that interests you, and don't be afraid to experiment with different genres and styles.\n",
      "\n",
      "2. Read widely: Reading widely will help you to develop your own writing style and to gain a deeper understanding of the craft of writing. Read books in your chosen genre, as well as books from other genres and from different time periods.\n",
      "\n",
      "3. Develop your ideas: Come up with ideas for stories, articles, or essays that you want to write. You can get ideas from your own life experiences, from current events, or from your own imagination.\n",
      "\n",
      "4. Revise and edit: Once you have written a draft, take the time to revise and edit it carefully. This will help you to identify areas that need improvement and to make your writing more cohesive and polished.\n",
      "\n",
      "5. Get feedback: Share your writing with others and ask for feedback. This can be from friends, family, or from writing groups or workshops. Use their feedback to improve your writing.\n",
      "\n",
      "6. Submit your work: Once you are confident in your writing, start submitting it to publishers, magazines, or websites that accept unsolicited submissions. You may need to submit many pieces before you are published, but perseverance is key.\n",
      "\n",
      "7. Promote your work: Once your work is published, promote it through social media, websites, and other channels. This will help you to build a following and to sell more copies of your book.\n",
      "\n",
      "Remember, becoming an author is a long-term process that requires dedication and hard work. Don't be discouraged by rejections or setbacks, and keep writing and improving your craft.\"\"\"\n",
      "    },\n",
      "    {\n",
      "        \"model\": \"model_2\",\n",
      "        \"answer\": \"\"\"Becoming an author involves a combination of hard work, dedication, and persistence. Here are some steps you can take to become an author:\n",
      "\n",
      "Write regularly: The key to becoming an author is to write regularly. Set aside time each day or each week to work on your writing projects. You can start by writing for a few minutes a day and gradually increase the amount of time you spend writing.\n",
      "\n",
      "Study the craft of writing: Learn the basics of grammar, punctuation, and syntax. Read widely in your chosen genre to learn from established authors. Take writing workshops, attend conferences, and join writing groups to get feedback on your work and learn from other writers.\n",
      "\n",
      "Develop a writing routine: Establish a routine for writing, such as setting aside a specific time each day or each week to work on your writing. This can help you build discipline and make writing a priority in your life.\n",
      "\n",
      "Write what you love: Write about topics and themes that you are passionate about. If you enjoy what you are writing, it will show in your work and it will be easier to maintain your motivation.\n",
      "\n",
      "Develop a thick skin: Writing is subjective, and not everyone will love your work. Learn to develop a thick skin and ignore negative feedback. Focus on improving your craft and creating work that you are proud of.\n",
      "\n",
      "Publish your work: Once you have written a manuscript, consider self-publishing or traditional publishing. Self-publishing allows you to control the process and get your work out there quickly, while traditional publishing can provide more recognition and support.\n",
      "\n",
      "Remember, becoming an author is a process that takes time and effort. Don't be discouraged by rejection or setbacks, and keep writing and improving your craft.\"\"\"\n",
      "    }\n",
      "]\n",
      "\n",
      "Now make the leaderboard by ranking the models by the quality of their answers, so that the model with rank 1 has the best output.\n",
      "<|im_end|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "instruction = \"I like to host guests at my home from time to time, and I am gathering  recipes of different dishes and drinks to keep things interesting. I am interested in trying some Danish dishes. Can you give me a recipe for Flæskesteg?\"\n",
    "\n",
    "#rlhf\n",
    "output_1 = \"\"\"Certainly! Flæskesteg is a traditional Danish roast pork dish that is typically served with potatoes and red cabbage. Here's a recipe for you to try:\\n\\nIngredients:\\n\\n    1.5 kg (3.3 lbs) boneless pork shoulder, trimmed of fat\\n    2 tbsp oil\\n    1 large onion, chopped\\n    1 carrot, chopped\\n    1 celery stalk, chopped\\n    1 tsp ground allspice\\n    1 tsp ground black pepper\\n    1 tsp salt\\n    3 cloves garlic, minced\\n    2 bay leaves\\n    1 tbsp vinegar\\n    2 tbsp beer\\n    1 tbsp molasses\\n    1 tbsp Worcestershire sauce\\n    Potatoes, peeled and cut into wedges\\n    Red cabbage, shredded\\n\\nInstructions:\\n\\n    Heat the oil in a large Dutch oven or roasting pan over medium heat. Add the onion, carrot, celery, and allspice and cook until softened, about 5 minutes.\\n\\n    Add the pork to the pan and cook, breaking it up with a spoon, until browned, about 10 minutes.\\n\\n    Add the garlic, bay leaves, vinegar, beer, molasses, Worcestershire sauce, and salt and pepper to taste. Bring to a boil, then reduce the heat to low and simmer, covered, for 1 hour.\\n\\n    Transfer the pork to a plate and set aside to rest for 10 minutes.\\n\\n    Add the potatoes to the pan and cook, stirring occasionally, until tender, about 20 minutes.\\n\\n    Add the red cabbage to the pan and cook, stirring occasionally, until heated through, about 5 minutes.\\n\\n    Slice the pork against the grain into thin slices. Serve the pork with the potatoes and cabbage, and enjoy!\\n\\nThis recipe should serve 4-6 people.\"\"\"\n",
    "output_2 = \"\"\"Flæskesteg is a classic Danish roast pork dish that is usually served as a main course during special occasions or holidays. Here's a recipe that you can try at home:\\n\\nIngredients:\\n\\n    2 pork loins (about 3-4 pounds each)\\n    2 tablespoons butter\\n    2 teaspoons salt\\n    1 teaspoon black pepper\\n    2 tablespoons brown sugar\\n    1/2 cup beer\\n    2 tablespoons cider vinegar\\n    1 large onion, sliced\\n    2 cloves garlic, minced\\n    1 tablespoon all-purpose flour\\n    1/2 cup heavy cream\\n    1/4 cup unsalted butter\\n    1/2 cup breadcrumbs\\n    1/4 cup chopped parsley\\n\\nInstructions:\\n\\n    Preheat the oven to 325°F (160°C).\\n    Place the pork loins in a large roasting pan and rub them with the butter.\\n    Sprinkle them with the salt, pepper, and brown sugar.\\n    Roast the pork for 1 hour, or until it is golden brown and slightly pink in the center.\\n    Remove the pork from the oven and cover it with foil.\\n    In a small saucepan, combine the beer, vinegar, onion, and garlic. Bring to a boil, reduce the heat to low, and simmer for 10 minutes.\\n    Remove the pan from the heat and let it cool for a few minutes.\\n    Whisk the flour into the cooled beer mixture until it forms a thick paste.\\n    In a separate saucepan, whisk the heavy cream until it thickens slightly.\\n    Pour the cream into the beer mixture and stir until well combined.\\n    Bring the mixture back to a simmer and cook for 2-3 minutes, or until it thickens slightly.\\n    Remove the pan from the heat and let it cool for a few minutes.\\n    Stir the butter into the sauce until it melts and combines with the sauce.\\n    Remove the pork from the foil and pour the sau\"\"\"\n",
    "\n",
    "instruction=\"How do you become an author?\"\n",
    "output_1=\"Becoming an author involves a combination of talent, hard work, and dedication. Here are some steps you can take to become an author:\\n\\n1. Write regularly: Practice your writing skills by writing every day, even if it's just for a few minutes. Write about anything that interests you, and don't be afraid to experiment with different genres and styles.\\n\\n2. Read widely: Reading widely will help you to develop your own writing style and to gain a deeper understanding of the craft of writing. Read books in your chosen genre, as well as books from other genres and from different time periods.\\n\\n3. Develop your ideas: Come up with ideas for stories, articles, or essays that you want to write. You can get ideas from your own life experiences, from current events, or from your own imagination.\\n\\n4. Revise and edit: Once you have written a draft, take the time to revise and edit it carefully. This will help you to identify areas that need improvement and to make your writing more cohesive and polished.\\n\\n5. Get feedback: Share your writing with others and ask for feedback. This can be from friends, family, or from writing groups or workshops. Use their feedback to improve your writing.\\n\\n6. Submit your work: Once you are confident in your writing, start submitting it to publishers, magazines, or websites that accept unsolicited submissions. You may need to submit many pieces before you are published, but perseverance is key.\\n\\n7. Promote your work: Once your work is published, promote it through social media, websites, and other channels. This will help you to build a following and to sell more copies of your book.\\n\\nRemember, becoming an author is a long-term process that requires dedication and hard work. Don't be discouraged by rejections or setbacks, and keep writing and improving your craft.\"\n",
    "#rlhf\n",
    "output_2=\"Becoming an author involves a combination of hard work, dedication, and persistence. Here are some steps you can take to become an author:\\n\\nWrite regularly: The key to becoming an author is to write regularly. Set aside time each day or each week to work on your writing projects. You can start by writing for a few minutes a day and gradually increase the amount of time you spend writing.\\n\\nStudy the craft of writing: Learn the basics of grammar, punctuation, and syntax. Read widely in your chosen genre to learn from established authors. Take writing workshops, attend conferences, and join writing groups to get feedback on your work and learn from other writers.\\n\\nDevelop a writing routine: Establish a routine for writing, such as setting aside a specific time each day or each week to work on your writing. This can help you build discipline and make writing a priority in your life.\\n\\nWrite what you love: Write about topics and themes that you are passionate about. If you enjoy what you are writing, it will show in your work and it will be easier to maintain your motivation.\\n\\nDevelop a thick skin: Writing is subjective, and not everyone will love your work. Learn to develop a thick skin and ignore negative feedback. Focus on improving your craft and creating work that you are proud of.\\n\\nPublish your work: Once you have written a manuscript, consider self-publishing or traditional publishing. Self-publishing allows you to control the process and get your work out there quickly, while traditional publishing can provide more recognition and support.\\n\\nRemember, becoming an author is a process that takes time and effort. Don't be discouraged by rejection or setbacks, and keep writing and improving your craft.\"\n",
    "input_prompt = f\"\"\"<|im_start|>system\n",
    "You are a helpful assistant, that makes a leaderboard of models based on the quality of their answers.\n",
    "<|im_end|>\n",
    "<|im_start|>user\n",
    "I want you to create a leaderboard of different of large-language models. To do so, I will give you the instructions (prompts) given to the models, and the responses of two models. To make a leaderboard, first make a list ranking the models based on which responses would be preferred by humans, then give the resulting list of JSON to `make_leaderboard`.\n",
    "\n",
    "Here is the prompt:\n",
    "{{\n",
    "    \"instruction\": \\\"\"\"{instruction}\\\"\"\",\n",
    "}}\n",
    "\n",
    "Here are the outputs of the models:\n",
    "[\n",
    "    {{\n",
    "        \"model\": \"model_1\",\n",
    "        \"answer\": \\\"\"\"{output_1}\\\"\"\"\n",
    "    }},\n",
    "    {{\n",
    "        \"model\": \"model_2\",\n",
    "        \"answer\": \\\"\"\"{output_2}\\\"\"\"\n",
    "    }}\n",
    "]\n",
    "\n",
    "Now make the leaderboard by ranking the models by the quality of their answers, so that the model with rank 1 has the best output.\n",
    "<|im_end|>\n",
    "\"\"\"\n",
    "\n",
    "print(input_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from openai import OpenAI\n",
    "import openai\n",
    "\n",
    "openai_api_keys = \"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\"\n",
    "base_url = openai.base_url\n",
    "\n",
    "client = OpenAI(base_url=base_url,api_key=openai_api_keys)\n",
    "\n",
    "client_kwargs = {\n",
    "    \"model\": \"gpt-4-1106-preview\",\n",
    "    \"max_tokens\": 100,\n",
    "    \"temperature\": 0,\n",
    "    \"top_p\":1.0,\n",
    "    \"function_call\": {\n",
    "      \"name\": \"make_leaderboard\"\n",
    "    },\n",
    "    \"functions\": [\n",
    "      {\n",
    "        \"name\": \"make_leaderboard\",\n",
    "        \"description\": \"Make a leaderboard of models given a list of the models ordered by the preference of their outputs.\",\n",
    "        \"parameters\": {\n",
    "          \"type\": \"object\",\n",
    "          \"properties\": {\n",
    "            \"ordered_models\": {\n",
    "              \"type\": \"array\",\n",
    "              \"description\": \"A list of models ordered by the preference of their outputs\",\n",
    "              \"items\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                  \"model\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The name of the model\"\n",
    "                  },\n",
    "                  \"rank\": {\n",
    "                    \"type\": \"number\",\n",
    "                    \"description\": \"Order of preference of the model, 1 has the best output\"\n",
    "                  }\n",
    "                }\n",
    "              }\n",
    "            }\n",
    "          }\n",
    "        },\n",
    "        \"required\": [\"ordered_models\"]\n",
    "      }\n",
    "    ]\n",
    "  }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "        messages=[{\"role\": \"user\", \"content\":input_prompt}],\n",
    "        **client_kwargs\n",
    "    )\n",
    "print(response.choices[0].message.function_call.arguments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "a = \"Lets try to fool vocabultary. Mean giahslflal tripallav vakunama tirakutti lafuddu\"\n",
    "enc = tiktoken.encoding_for_model(client_kwargs[\"model\"])\n",
    "assert enc.decode(enc.encode(a)) == a\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_p310_ppo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
