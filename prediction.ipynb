{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================== Initialize from adapter output/LLama-2-7b_pre_sft_4bit_lr_1e5_bs_64_adam_hf/final_checkpoint\n",
      "\n",
      "============================== Following are the configuration for training==============================\n",
      "!!python/object:argparse.Namespace\n",
      "adam_beta1: 0.9\n",
      "adam_beta2: 0.95\n",
      "adam_epsilon: 1e-12\n",
      "adapter_number: final_checkpoint\n",
      "adpater_name: null\n",
      "checkpoint_name: null\n",
      "checkpoint_number: final_checkpoint\n",
      "collator:\n",
      "  label_masking: true\n",
      "  random_offset_probability: 0.5\n",
      "  samples_mixing: true\n",
      "  system_prefix: null\n",
      "  use_system_prefix: false\n",
      "  val_max_length: 2048\n",
      "dataset:\n",
      "  alpaca:\n",
      "    max_val_set: 200\n",
      "    val_split: 0.05\n",
      "  dolly:\n",
      "    max_val_set: 300\n",
      "    val_split: 0.05\n",
      "  math_instruction:\n",
      "    max_val_set: 200\n",
      "    val_split: 0.05\n",
      "  oasst_export:\n",
      "    lang: en,bg,ca,cs,da,de,en,es,fr,hr,hu,it,nl,pl,pt,ro,ru,sl,sr,sv,uk\n",
      "    max_val_set: null\n",
      "    val_split: 0.05\n",
      "  vicuna:\n",
      "    max_val_set: 800\n",
      "    val_split: 0.05\n",
      "debug: false\n",
      "debug_set: 100\n",
      "dtype: bf16\n",
      "eval_accumulation_steps: null\n",
      "eval_batch: 4\n",
      "eval_steps: 100\n",
      "gradient_accumulation_steps: 16\n",
      "gradient_checkpointing: true\n",
      "hpt_data_frac: null\n",
      "init_from_adapter: output/LLama-2-7b_pre_sft_4bit_lr_1e5_bs_64_adam_hf/final_checkpoint\n",
      "int4_training: true\n",
      "int8_training: false\n",
      "is_abs_rm: null\n",
      "log_steps: 25\n",
      "lr: 1e-5\n",
      "lr_scheduler_type: cosine\n",
      "model_name: meta-llama/Llama-2-7b-hf\n",
      "name: LLama-2-7b_eval\n",
      "name_suffix: ''\n",
      "num_train_epochs: 1\n",
      "oasst_sft: LLama-2-7b_oasst_sft\n",
      "optuna: false\n",
      "output_dir: output\n",
      "pre_sft: LLama-2-7b_pre_sft\n",
      "ranking_rm: LLama-2-7b_ranking_reward\n",
      "report_to: wandb\n",
      "resume_from_checkpoint: null\n",
      "save_steps: 300\n",
      "subset: sft_eval\n",
      "train_batch: 4\n",
      "warmup_steps: 20\n",
      "weight_decay: 1.0e-06\n",
      "\n",
      "loading meta-llama/Llama-2-7b-hf model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer size 32003\n",
      "Resizing embeddings to 32016\n",
      "===loading the vicuna dataset===\n",
      "\n",
      "Size of vicuna training data: 55858\n",
      "Size of vicuna validation data: 800\n",
      "===loading the dolly dataset===\n",
      "\n",
      "Size of dolly training data: 14250\n",
      "Size of dolly validation data: 300\n",
      "===loading the alpaca dataset===\n",
      "\n",
      "Size of alpaca training data: 19019\n",
      "Size of alpaca validation data: 200\n",
      "===loading the math_instruction dataset===\n",
      "\n",
      "[Warning] 1 entries of Dataset({\n",
      "    features: ['INSTRUCTION', 'RESPONSE', 'SOURCE'],\n",
      "    num_rows: 8792\n",
      "}) were invalid.\n",
      "Size of math_instruction training data: 8351\n",
      "Size of math_instruction validation data: 200\n",
      "===loading the oasst_export dataset===\n",
      "\n",
      "OASST HF dataset: len(train)=38192, len(eval)=1992\n",
      "============================== Total training dataset size is 135670...\n",
      "\t============================== Validation size for vicuna dataset size is 800...\n",
      "\t============================== Validation size for dolly dataset size is 300...\n",
      "\t============================== Validation size for alpaca dataset size is 200...\n",
      "\t============================== Validation size for math_instruction dataset size is 200...\n",
      "\t============================== Validation size for oasst_export dataset size is 1992...\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "\n",
    "from utils import (print_yaml_config,init_or_resume_from, read_yaml)\n",
    "from model_training.training_utils import load_for_inference\n",
    "from constants import TOKENIZER_SEPECIAL_TOKENS\n",
    "from training_datasets.dataset_utils import load_sft_dataset, load_rm_dataset\n",
    "from training_datasets.collators import DialogueDataCollator\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main(conf):\n",
    "    print(f\"\\n{'==='*10} Following are the configuration for training{'==='*10}\")\n",
    "    print_yaml_config(conf)\n",
    "    \n",
    "    device_map = {\"\":0}\n",
    "    assert \"llama\" in conf.model_name.lower(), \"Currently only llama model supported\"\n",
    "    special_tokens = TOKENIZER_SEPECIAL_TOKENS[\"llama\"]\n",
    "    model, tokenizer = load_for_inference(device_map,conf,special_tokens,conf.model_name,False)\n",
    "    _ , eval_ds = load_sft_dataset(conf,special_tokens[\"eos_token\"])\n",
    "\n",
    "    eval_collate_fn = DialogueDataCollator(\n",
    "        tokenizer,\n",
    "        max_length=conf.collator[\"val_max_length\"],\n",
    "        random_offset_probability=conf.collator[\"random_offset_probability\"],\n",
    "        label_masking=conf.collator[\"label_masking\"],\n",
    "        samples_mixing=False,\n",
    "        use_system_prefix=conf.collator[\"use_system_prefix\"],\n",
    "        system_prefix=conf.collator[\"system_prefix\"],\n",
    "        )\n",
    "    return model, eval_ds, eval_collate_fn, tokenizer\n",
    "\n",
    "config = {}\n",
    "conf = read_yaml('./config.yaml')\n",
    "config.update(conf[\"default\"])\n",
    "config.update(conf[\"sft_eval\"])\n",
    "config[\"name_suffix\"] = \"\"\n",
    "config[\"debug\"] = False\n",
    "config[\"subset\"] = \"sft_eval\"\n",
    "\n",
    "# Create a Namespace object for config\n",
    "config_ns = argparse.Namespace(**config)\n",
    "\n",
    "\n",
    "init_or_resume_from(config_ns)\n",
    "# config_ns.model_name = config_ns.base_model_name\n",
    "model, eval_ds, collator, tokenizer = main(config_ns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    }
   ],
   "source": [
    "# data = eval_ds[\"vicuna\"][0]\n",
    "# tokens = collator([data])\n",
    "input = \"\"\"<|prompter|>When was google created? Why did it dominate over other search engines?<s><|assistant|>\"\"\"\n",
    "tokens = tokenizer(input,return_tensors='pt').to(\"cuda:0\")\n",
    "\n",
    "print(len(tokens.input_ids[0]))\n",
    "# label_masks = tokens.pop(\"label_masks\")\n",
    "# targets = tokens.pop(\"targets\")\n",
    "\n",
    "output = model.generate(**tokens,\n",
    "                        max_new_tokens=400,\n",
    "                        do_sample=True,\n",
    "                        top_p=0.9,\n",
    "                        top_k=0,\n",
    "                        repetition_penalty=1.2,\n",
    "                        temperature=0.8)\n",
    "# import torch\n",
    "\n",
    "# with torch.no_grad():\n",
    "#         outputs = model(\n",
    "#             input_ids=tokens[\"input_ids\"],\n",
    "#             use_cache=False,\n",
    "#         )\n",
    "\n",
    "# logits = outputs.get(\"logits\")\n",
    "# pred_ids = torch.argmax(logits, dim=-1)\n",
    "# len(pred_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "<s><|prompter|> When was google created? Why did it dominate over other search engines?<s><|assistant|> Google was founded by Larry Page and Sergey Brin in 1998.\n",
      "Google's success can be attributed to several factors, including its ability to quickly index the vast amount of information available online, its simple user interface that allows users to easily navigate through the search results, and its emphasis on providing high-quality search results based on a complex algorithm known as PageRank . Additionally, Google has also developed various products and services such as Gmail, YouTube, Android operating system for mobile devices, etc., which have further increased its popularity among internet users</s>\n"
     ]
    }
   ],
   "source": [
    "print(\"Output:\\n\" + 100 * '-')\n",
    "print(tokenizer.decode(output[0], skip_special_tokens=False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"the game scores the difference between their score and the total of all the other players' scores.\\n\\nI hope this helps you create a fun and exciting Rummy-based card game! Let me know if you have any further questions.</s><|prompter|> I am going to add a mechanic to the game where players can choose a new rule to add to the game after every round. These new rules are written on cards called Rule Cards. The players can look at the Rule Cards and choose one. The rule written on the card will then be in effect for the rest of the game. If I give you the examples of Rule Cards that I have already thought of, can you help me think of more of them?</s><|assistant|> Certainly! I'd be happy to help you come up with more Rule Cards. What are the examples of Rule Cards that you have already thought of? Knowing those can help me come up with additional ideas that fit with the theme and mechanics of your game.</s><|prompter|> 1. Wild Cards - different cards can be wild\\n2. Change the number of cards dealt to each player\\n3. Everyone plays with their cards face up so the other players can see them\\n4. Discarding cards is optional\\n5. You can pick up the entire discard pile instead of just one card\\n6. A run can now be different suits\\n7. You now need at least 4 cards in a run</s><|assistant|> Great! Here are some additional Rule Cards you can consider adding:\\n\\n1. Seven pairs - In addition to runs and sets, players can also form seven pairs to win the game. A seven pair is formed by having seven pairs of cards of the same rank.\\n2. Three of a kind - Instead of sets of three or four cards, players must now form sets of exactly three cards to win.\\n3. No Melding - Players cannot form sets or runs during their turn.\\n4. Straight Flush - Players must form runs of the same suit to win the game.\\n5. Ace High/Low - Players can choose to use the Ace as either the highest or lowest card in runs.\\n6. Five or More - Players must form runs or sets of at least five cards to win the game.\\n7. Progressive Runs - Players must form runs in sequential order, with each run adding one card to the previous run.\\n8. No Discards - Players cannot discard any cards during their turn.\\n9. Skip Turn - Players can choose to skip their turn to draw an extra card from the deck.\\n10. Reverse Order - Play proceeds counter-clockwise instead of clockwise.\\n11. Double Run - Players must form two runs to win the game.\\n12. No Wild Cards - Wild cards are not allowed to be used in sets or runs.\\n13. Four of a kind - Players must form sets of exactly four cards to win.\\n14. Trade - Players can trade one card from their hand with any one card in the discard pile.\\n15. Time Limit - Players must discard a card within a certain amount of time or be penalized.\\n\\nI hope these Rule Cards give you some inspiration for your game! Let me know if you need any further assistance.</s><|prompter|> We are thinking of using two decks of cards for the game, instead of just one. Does that give you any other ideas for Rule Cards?</s><|assistant|> Using two decks of cards opens up more possibilities for Rule Cards. Here are some additional ideas:\\n\\n1. Double Deuces - In addition to the regular wild cards, Deuces (2s) are also wild.\\n2. Cutthroat - Players can steal a set or run from another player by adding a card to it during their turn.\\n3. Limited Wild Cards - Only a certain number of wild cards can be used in a single set or run.\\n4. Double Rummy - Players must form two sets or runs to win the game.\\n5. Tricky Trios - In addition to sets and runs, players can also form trios, which are sets of three cards of the same rank and the same suit.\\n6. Suit Swap - Players can swap the suits of two cards in their hand.\\n7. Jokers - Joker cards are added to the deck and can be used as wild cards.\\n8. Four Color Deck - A four-color deck is used instead of a standard deck, with each suit having a unique color.\\n9. Multiple Discard Piles - There are two or more discard piles, and players can choose which one to draw from.\\n10. Deck Swap - The two decks are swapped after a certain number of rounds.\\n11. Double Trouble - Two cards of the same rank and suit must be used in every set or run.\\n12. Auction - Players bid on the number of cards they think they can meld in a single turn, with the highest bidder being the first to play.\\n13. No Sets - Players can only form runs to win the game.\\n14. Scramble - All players pass their hand to the player on their left after a certain number of rounds.\\n15. Three Decks - Three decks are used instead of two, with players drawing from one deck at a time.\\n\\nI hope these additional Rule Cards help add some variety to your game using two decks of cards! Let me know if you have any further questions or need any more assistance.</s><|prompter|> We also want to have some Rule Cards that change the social aspect of the game. Here are a couple of examples:\\n\\n1. Everyone has to talk like a pirate. You lose points if you forget.\\n2. No one can talk for one round. If you forget then you have to draw another card.\\n\\nDo you have any other ideas for Rule Cards that are more social?</s><|assistant|> Sure! Here are some social Rule Cards you can consider adding to your game:\\n\\n1. Impersonations - Players must impersonate a famous person or character during their turn, and lose points if they break character.\\n2. Accents - Players must speak in a specific accent during their turn, chosen by the player who drew the Rule Card.\\n3. Singing - Players must sing their turn instead of speaking, and lose points if they forget the lyrics.\\n4. Rhyme Time - Players must speak in rhyming couplets during their turn, and lose points if they break the rhyme.\\n5. Charades - Players must act out the cards they are playing instead of speaking during their turn.\\n6. Truth or Dare - Players can choose to either answer a truth question or perform a dare during their turn, chosen by the player who drew the Rule Card.\\n7. Puns - Players must use puns during their turn, and lose points if they fail to come up with a pun.\\n8. Word Association - Players must say a word related to the card they are playing during their turn, and lose points if they fail to come up with a word.\\n9. Tongue Twisters - Players must say a tongue twister before playing their cards during their turn, and lose points if they mess up the twister.\\n10. Alphabet Game - Players must say a word starting with the next letter of the alphabet during their turn, and lose points if they fail to come up with a word.\\n\\nI hope these social Rule Cards help add some fun and variety to your game! Let me know if you have any further questions or need any more assistance.</s><|prompter|> I like the Rule Card that limits the amount of time per turn. Can you think of a good way for the players to know when their time is up if we don't include a timer in the game?</s><|assistant|> If you don't want to include a timer in the game, there are other ways to let players know when their time is up. Here are a few ideas:\\n\\n1. Use a Sand Timer - While you mentioned that you don't want to include a timer in the game, a sand timer could be a simple and fun way to keep track of time without needing a digital device.\\n2. Use a Countdown - You can use a countdown method where players have a set amount of time (e.g., 30 seconds) to play their turn, and a designated player (e.g., the player to their left) counts down out loud to let them know when their time is up.\\n3. Use a Musical Cue - You can play a short musical cue (e.g., a few seconds of a song) to signal the end of the turn. This can be a fun way to incorporate music into the game and create a memorable experience.\\n4. Use a Light or Bell - You can use a flashing light or bell to signal the end of the turn. This can be especially helpful if players have difficulty hearing or if the game is being played in a loud environment.\\n5. Use a Turn Tracker - You can use a turn tracker, such as a numbered card, to keep track of the number of turns each player has taken. When the turn tracker reaches a certain number (e.g., five turns), the player must end their turn, regardless of how much time they have left.\\n\\nI hope these\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokens.input_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|prompter|>Write a function to create a retail price tag given a cost, taxes and discounts.\n",
      "cost = 5\n",
      "tax = 0.08\n",
      "discount = 0.2</s><|assistant|>def price_tag(cost, tax, discount):\n",
      "  tax_amount = cost * tax \n",
      "  discounted_price = cost + tax_amount - (discount * cost)\n",
      "  return \"Retail Price: $\" + str(round(discounted_price, 2))\n",
      "\n",
      "price_tag(cost, tax, discount) # returns \"Retail Price: $7.20\"</s>\n"
     ]
    }
   ],
   "source": [
    "print(\"\".join(eval_ds[\"alpaca\"][6]))\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.generate\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_p310_setup",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
